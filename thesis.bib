% Encoding: UTF-8

@PhdThesis{Rockai15,
  author     = {Ro{\v c}kai, Petr},
  title      = {Model Checking Software [online]},
  school     = {Masaryk University, Faculty of Informatics, Brno},
  year       = {2015 [cit. 2017-06-10]},
  type       = {Doctoral theses, Dissertations},
  supervisor = {Barnat, Ji{\v r}{\' i}},
  url        = {http://is.muni.cz/th/139761/fi_d/},
}

@Article{King76,
  author     = {King, James C.},
  title      = {Symbolic Execution and Program Testing},
  journal    = {Commun. ACM},
  year       = {1976},
  volume     = {19},
  number     = {7},
  pages      = {385--394},
  month      = jul,
  issn       = {0001-0782},
  acmid      = {360252},
  address    = {New York, NY, USA},
  issue_date = {July 1976},
  keywords   = {program debugging, program proving, program testing, program verification, symbolic execution, symbolic interpretation},
  numpages   = {10},
  publisher  = {ACM},
}

@InBook{Khurshid03,
  pages     = {553--568},
  title     = {Generalized Symbolic Execution for Model Checking and Testing},
  publisher = {Springer Berlin Heidelberg},
  year      = {2003},
  author    = {Khurshid, Sarfraz and P{\u{a}}s{\u{a}}reanu, Corina S. and Visser, Willem},
  editor    = {Garavel, Hubert and Hatcliff, John},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-36577-8},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems: 9th International Conference, TACAS 2003 Held as Part of the Joint European Conferences on Theory and Practice of Software, ETAPS 2003 Warsaw, Poland, April 7--11, 2003 Proceedings},
}

@InBook{Mrazek16,
  pages     = {208--213},
  title     = {SymDIVINE: Tool for Control-Explicit Data-Symbolic State Space Exploration},
  publisher = {Springer International Publishing},
  year      = {2016},
  author    = {Mr{\'a}zek, Jan and Bauch, Petr and Lauko, Henrich and Barnat, Ji{\v{r}}{\'i}},
  editor    = {Bo{\v{s}}na{\v{c}}ki, Dragan and Wijs, Anton},
  address   = {Cham},
  isbn      = {978-3-319-32582-8},
  booktitle = {Model Checking Software: 23rd International Symposium, SPIN 2016, Co-located with ETAPS 2016, Eindhoven, The Netherlands, April 7-8, 2016, Proceedings},
}

@Book{Clarke99,
  title     = {Model checking},
  publisher = {MIT press},
  year      = {1999},
  author    = {Clarke, Edmund M and Grumberg, Orna and Peled, Doron},
}

@InProceedings{Barnat14,
  author    = {Barnat, Ji{\v{r}}{\'i} and Bauch, Petr and Havel, Vojta},
  title     = {Model Checking Parallel Programs with Inputs},
  booktitle = {2014 22nd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing},
  year      = {2014},
  pages     = {756-759},
  issn      = {1066-6192},
  keywords  = {computability;parallel programming;program verification;temporal logic;LTL model checking;explicit approach;input variables;linear temporal logic;noncanonical representations;parallel program model checking;parallel program verification;quantified bit-vector formulae;quantifier-free satisfiability;state matching;state space representation;state space searching;symbolic approach;Concrete;Educational institutions;Input variables;Model checking;Protocols;Scalability;Standards;bit-vector theory;concurrency verification;ltl model checking;satisfiability modulo theories},
}

@InProceedings{Cousot79,
  author    = {Cousot, Patrick and Cousot, Radhia},
  title     = {Systematic design of program analysis frameworks},
  booktitle = {Conference Record of the Sixth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  year      = {1979},
  pages     = {269--282},
  address   = {San Antonio, Texas},
  publisher = {ACM Press, New York, NY},
}

@InProceedings{Lattner04,
  author    = {Lattner, Chris and Adve, Vikram},
  title     = {LLVM: A Compilation Framework for Lifelong Program Analysis \& Transformation},
  booktitle = {Proceedings of the International Symposium on Code Generation and Optimization: Feedback-directed and Runtime Optimization},
  year      = {2004},
  series    = {CGO '04},
  pages     = {75--},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {977673},
  isbn      = {0-7695-2102-9},
  location  = {Palo Alto, California},
  url       = {http://dl.acm.org/citation.cfm?id=977395.977673},
}

@online{LLVM:web,
  author = {Chris Lattner},
  title  = {The \LLVM Compiler Infrastructure Project},
  url    = {http://llvm.org/},
  urldate = {2017-13-09},
  year = {2017}
}

@online{LLVM:langref,
  author = {{LLVM~Project}},
  title  = {LLVM Language Reference Manual},
  url    = {http://llvm.org/docs/LangRef.html},
  urldate = {2017-13-09},
  year = {2017}
}

@Book{Winskel93,
  title     = {The Formal Semantics of Programming Languages: An Introduction},
  publisher = {MIT Press},
  year      = {1993},
  author    = {Winskel, Glynn},
  address   = {Cambridge, MA, USA},
  isbn      = {0-262-23169-7},
}

@Article{Plotkin04,
  author  = {Gordon D{.} Plotkin},
  title   = {The origins of structural operational semantics},
  journal = {The Journal of Logic and Algebraic Programming},
  year    = {2004},
  volume  = {60},
  number  = {Supplement C},
  pages   = {3 - 15},
  issn    = {1567-8326},
  note    = {Structural Operational Semantics},
  url     = {http://www.sciencedirect.com/science/article/pii/S1567832604000268},
}

@Online{LLVM:opt,
  author  = {Chris Lattner},
  title   = {OPT \LLVM optimizer},
  year    = {2017},
  url     = {http://llvm.org/docs/CommandGuide/opt.html},
  urldate = {2017-23-09},
}

@Book{Baier08,
  title     = {Principles of Model Checking (Representation and Mind Series)},
  publisher = {The MIT Press},
  year      = {2008},
  author    = {Baier, Christel and Katoen, Joost-Pieter},
  isbn      = {026202649X, 9780262026499},
}

@Article{Clarke94,
  author     = {Clarke, Edmund M{.} and Grumberg, Orna and Long, David E{.}},
  title      = {Model Checking and Abstraction},
  journal    = {ACM Trans. Program. Lang. Syst.},
  year       = {1994},
  volume     = {16},
  number     = {5},
  pages      = {1512--1542},
  month      = sep,
  issn       = {0164-0925},
  acmid      = {186051},
  address    = {New York, NY, USA},
  issue_date = {Sept. 1994},
  keywords   = {abstract interpretation, binary decision diagrams (BDDs), model checking, temporal logic},
  numpages   = {31},
  publisher  = {ACM},
}

@Article{Divine17,
  author = {Baranov\'{a}, Zuzana and Barnat, Ji\v{r}\'{i} and  Kejstov\'{a}, Katar\'{i}na and Ku{\v c}era, Tade{\'{a}}{\v{s}} and  Lauko, Henrich and Mr{\'a}zek, Jan and  Ro{\v {c}}kai, Petr and  {\v{S}}till, Vladim\'{i}r},
  title  = {Model Checking of {C} and {C}++ with {DIVINE} 4},
  year   = {2017},
  note   = {Preliminary version.},
  url    = {https://divine.fi.muni.cz/2017/divine4},
}

@Article{RockaiCB17,
  author    = {Ro{\v c}kai, Petr and Ivana {\v C}ern{\'{a}} and Barnat, Ji\v{r}\'{i}},
  title     = {DiVM: Model Checking with {LLVM} and Graph Memory},
  journal   = {CoRR},
  year      = {2017},
  volume    = {abs/1703.05341},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/RockaiCB17},
  timestamp = {Wed, 07 Jun 2017 14:42:01 +0200},
  url       = {http://arxiv.org/abs/1703.05341},
}

@MastersThesis{Still16,
  author     = {{\v S}till, Vladim\'ir},
  title      = {LLVM Transformations for Model Checking [online]},
  school     = {Masaryk University, Facult of Informatics, Brno},
  year       = {2016 [cit. 2017-10-08]},
  type       = {Diploma theses},
  supervisor = {Barnat, Ji\v{r}\'{i}},
  url        = {https://is.muni.cz/th/373979/fi_m/},
}

@InProceedings{Still17,
  author    = {{\v S}till, Vladim\'ir and Ro{\v c}kai, Petr and Barnat, Ji\v{r}\'{i}},
  title     = {{Using Off-the-Shelf Exception Support Components in C++ Verification}},
  booktitle = {IEEE International Conference on Software Quality, Reliability and Security (QRS)},
  year      = {2017},
  pages     = {54-64},
  month     = {July},
  keywords  = {C++ languages, Libraries, Software, Standards, Testing, Tools, C++, Exceptions, Model Checking, Unwinder, divine, exceptions, red hat},
  page      = {https://divine.fi.muni.cz/2017/exceptions/},
  url       = {http://ieeexplore.ieee.org/document/8009908/},
}

@InBook{Bauch14,
  pages     = {47--59},
  title     = {LTL Model Checking of LLVM Bitcode with Symbolic Data},
  publisher = {Springer International Publishing},
  year      = {2014},
  author    = {Bauch, Petr and Havel, Vojt{\v{e}}ch and Barnat, Ji{\v{r}}{\'i}},
  editor    = {Hlin{\v{e}}n{\'y}, Petr and Dvo{\v{r}}{\'a}k, Zden{\v{e}}k and Jaro{\v{s}}, Ji{\v{r}}{\'i} and Kofro{\v{n}}, Jan and Ko{\v{r}}enek, Jan and Matula, Petr and Pala, Karel},
  address   = {Cham},
  isbn      = {978-3-319-14896-0},
  abstract  = {The correctness of parallel and reactive programs is often easier specified using formulae of temporal logics. Yet verifying that a system satisfies such specifications is more difficult than verifying safety properties: the recurrence of a specific program state has to be detected. This paper reports on the development of a generic framework for automatic verification of linear temporal logic specifications for programs in LLVM bitcode. Our method searches explicitly through all possible interleavings of parallel threads (control non-determinism) but represents symbolically the variable evaluations (data non-determinism), guided by the specification in order to prove the correctness. To evaluate the framework we compare our method with state-of-the-art tools on a set of unmodified C programs.},
  booktitle = {Mathematical and Engineering Methods in Computer Science: 9th International Doctoral Workshop, MEMICS 2014, Tel{\v{c}}, Czech Republic, October 17--19, 2014, Revised Selected Papers},
}

@InBook{Rockai13,
  pages     = {1--15},
  title     = {Improved State Space Reductions for LTL Model Checking of C and C++ Programs},
  publisher = {Springer Berlin Heidelberg},
  year      = {2013},
  author    = {Ro{\v{c}}kai, Petr and Barnat, Ji{\v{r}}{\'i} and Brim, Lubo{\v{s}}},
  editor    = {Brat, Guillaume and Rungta, Neha and Venet, Arnaud},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-38088-4},
  abstract  = {In this paper, we present substantial improvements in efficiency of explicit-state LTL model checking of C {\&} C++ programs, building on [2], including improvements to state representation and to state space reduction techniques. The improved state representation allows to easily exploit symmetries in heap configurations of the program, especially in programs with interleaved heap allocations. Finally, we present a major improvement through a semi-dynamic proviso for partial-order reduction, based on eager local searches constrained through control-flow loop detection.},
  booktitle = {NASA Formal Methods: 5th International Symposium, NFM 2013, Moffett Field, CA, USA, May 14-16, 2013. Proceedings},
}

@MastersThesis{Havel14,
  author     = {Havel, Vojt{\v e}ch},
  title      = {Generic Platform for Explicit-Symbolic Verification [online]},
  school     = {Masaryk University, Faculty of Informatics, Brno},
  year       = {2014 [cit. 2017-10-14]},
  type       = {Diploma theses},
  supervisor = {Barnat, Ji{\v r}{\'i} },
  url        = {http://is.muni.cz/th/359437/fi_m/},
}

@Article{Cytron91,
  author     = {Cytron, Ron and Ferrante, Jeanne and Rosen, Barry K. and Wegman, Mark N. and Zadeck, F. Kenneth},
  title      = {Efficiently Computing Static Single Assignment Form and the Control Dependence Graph},
  journal    = {ACM Trans. Program. Lang. Syst.},
  year       = {1991},
  volume     = {13},
  number     = {4},
  pages      = {451--490},
  month      = oct,
  issn       = {0164-0925},
  acmid      = {115320},
  address    = {New York, NY, USA},
  issue_date = {Oct. 1991},
  keywords   = {control dependence, control flow graph, def-use chain, dominator, optimizing compilers},
  numpages   = {40},
  publisher  = {ACM},
}

@InProceedings{Hadarean14,
  author = {Liana Hadarean},
  title  = {An Efficient and Trustworthy Theory Solver for Bit-vectors in Satisfiability Modulo Theories},
  year   = {2014},
}

@InProceedings{duret04,
  author      = {Duret-Lutz, Alexandre and Poitrenaud, Denis},
  title       = {{SPOT: an Extensible Model Checking Library using Transition-based Generalized B{\"u}chi Automata}},
  booktitle   = {{12th IEEE/ACM International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS '04)}},
  year        = {2004},
  pages       = {76-83},
  address     = {Volendam, Netherlands},
  month       = Oct,
  publisher   = {{IEEE Computer Society Press}},
  hal_id      = {hal-01496158},
  hal_version = {v1},
  url         = {https://hal.archives-ouvertes.fr/hal-01496158},
}

@InBook{Vardi96,
  pages     = {238--266},
  title     = {An automata-theoretic approach to linear temporal logic},
  publisher = {Springer Berlin Heidelberg},
  year      = {1996},
  author    = {Vardi, Moshe Y.},
  editor    = {Moller, Faron and Birtwistle, Graham},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-49675-5},
  abstract  = {The automata-theoretic approach to linear temporal logic uses the theory of automata as a unifying paradigm
for program specification, verification, and synthesis. Both programs and specifications are in essence descriptions
of computations. These computations can be viewed as words over some alphabet. Thus, programs and specifications can
be viewed as descriptions of languages over some alphabet. The automata-theoretic perspective considers the
relationships between programs and their specifications as relationships between languages. By translating programs
and specifications to automata, questions about programs and their specifications can be reduced to questions about
automata. More specifically, questions such as satisfiability of specifications and correctness of programs with
respect to their specifications can be reduced to questions such as nonemptiness and containment of automata.},
  booktitle = {Logics for Concurrency: Structure versus Automata},
}

@Book{Manna92,
  title     = {The Temporal Logic of Reactive and Concurrent Systems},
  publisher = {Springer-Verlag New York, Inc.},
  year      = {1992},
  author    = {Manna, Zohar and Pnueli, Amir},
  address   = {New York, NY, USA},
  isbn      = {0-387-97664-7},
}

@InBook{Clarke96,
  pages     = {419--422},
  title     = {Symbolic model checking},
  publisher = {Springer Berlin Heidelberg},
  year      = {1996},
  author    = {Clarke, E. and McMillan, K. and Campos, S. and Hartonas-Garmhausen, V.},
  editor    = {Alur, Rajeev and Henzinger, Thomas A.},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-68599-9},
  abstract  = {Symbolic model checking is a powerful formal specification and
verification method that has been applied successfully in several industrial
designs. Using symbolic model checking techniques it is possible to verify
industrial-size finite state systems. State spaces with up to 1030 states can
be exhaustively searched in minutes. Models with more than 10120 states have
been verified using special techniques.},
  booktitle = {Computer Aided Verification: 8th International Conference, CAV '96 New Brunswick, NJ, USA, July 31-- August 3, 1996 Proceedings},
}

@Book{McMillan93,
  title     = {Symbolic Model Checking},
  publisher = {Kluwer Academic Publishers},
  year      = {1993},
  author    = {McMillan, Kenneth L.},
  address   = {Norwell, MA, USA},
  isbn      = {0792393805},
}

@Article{Cimatti20,
  author   = {Cimatti, Alessandro and Clarke, Edmund and Giunchiglia, Fausto and Roveri, Marco},
  title    = {NUSMV: a new symbolic model checker},
  journal  = {International Journal on Software Tools for Technology Transfer},
  year     = {2000},
  volume   = {2},
  number   = {4},
  pages    = {410--425},
  month    = {Mar},
  issn     = {1433-2779},
  abstract = {This paper describes a new symbolic model checker, called NuSMV, developed as part of a joint project between CMU and IRST. NuSMV is the result of the reengineering, reimplementation and, to a limited extent, extension of the CMU SMV model checker. The core of this paper consists of a detailed description of the NuSMV functionalities, architecture, and implementation.},
  day      = {01},
}

@InBook{Kwiatkowska20,
  pages     = {200--204},
  title     = {PRISM: Probabilistic Symbolic Model Checker},
  publisher = {Springer Berlin Heidelberg},
  year      = {2002},
  author    = {Kwiatkowska, Marta and Norman, Gethin and Parker, David},
  editor    = {Field, Tony and Harrison, Peter G. and Bradley, Jeremy and Harder, Uli},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-46029-9},
  abstract  = {In this paper we describe PRISM, a tool being developed at the University of Birmingham for the analysis of probabilistic systems. PRISM supports three probabilistic models: discrete-time Markov chains, Markov decision processes and continuous-time Markov chains. Analysis is performed through model checking such systems against specifications written in the probabilistic temporal logics PCTL and CSL. The tool features three model checking engines: one symbolic, using BDDs (binary decision diagrams) and MTBDDs (multi-terminal BDDs); one based on sparse matrices; and one which combines both symbolic and sparse matrix methods. PRISM has been successfully used to analyse probabilistic termination, performance, and quality of service properties for a range of systems, including randomized distributed algorithms, manufacturing systems and workstation clusters.},
  booktitle = {Computer Performance Evaluation: Modelling Techniques and Tools: 12th International Conference, TOOLS 2002 London, UK, April 14--17, 2002 Proceedings},
}

@Article{Havelund20,
  author   = {Havelund, Klaus and Pressburger, Thomas},
  title    = {Model checking JAVA programs using JAVA PathFinder},
  journal  = {International Journal on Software Tools for Technology Transfer},
  year     = {2000},
  volume   = {2},
  number   = {4},
  pages    = {366--381},
  month    = {Mar},
  issn     = {1433-2779},
  abstract = {This paper describes a translator called Java PathFinder (Jpf), which translates from Java to Promela, the modeling language of the Spin model checker. Jpf translates a given Java program into a Promela model, which then can be model checked using Spin. The Java program may contain assertions, which are translated into similar assertions in the Promela model. The Spin model checker will then look for deadlocks and violations of any stated assertions. Jpf generates a Promela model with the same state space characteristics as the Java program. Hence, the Java program must have a finite and tractable state space. This work should be seen in a broader attempt to make formal methods applicable within NASA's areas such as space, aviation, and robotics. The work is a continuation of an effort to formally analyze, using Spin, a multi-threaded operating system for the Deep-Space 1 space craft, and of previous work in applying existing model checkers and theorem provers to real applications.},
  day      = {01},
}

@Article{Cousot14,
  author = {Cousot, Patrick and Cousot, Radhia},
  title  = {Abstract interpretation: past, present and future},
  year   = {2014},
  month  = {07},
  isbn   = {978-1-4503-2886-9},
}

@Article{Holzmann97,
  author     = {Holzmann, Gerard J.},
  title      = {The Model Checker SPIN},
  journal    = {IEEE Trans. Softw. Eng.},
  year       = {1997},
  volume     = {23},
  number     = {5},
  pages      = {279--295},
  month      = may,
  issn       = {0098-5589},
  acmid      = {260902},
  address    = {Piscataway, NJ, USA},
  issue_date = {May 1997},
  keywords   = {Formal methods, program verification, design verification, model checking, distributed systems, concurrency.},
  numpages   = {17},
  publisher  = {IEEE Press},
}

@InProceedings{redlib,
  author    = {F. Wang},
  title     = {REDLIB for the Formal Verification of Embedded Systems},
  booktitle = {Second International Symposium on Leveraging Applications of Formal Methods, Verification and Validation (isola 2006)},
  year      = {2006},
  pages     = {341-346},
  month     = {Nov},
  keywords  = {Boolean functions;automata theory;embedded systems;formal verification;Boolean operations;dense-time automata;dense-time state-space;dynamic memory allocation;embedded systems;formal verification;linear hybrid systems;parametric safety analysis;state-space operations;state-space representation normalizations;Automata;Boolean functions;Data structures;Embedded system;Formal verification;Graphical user interfaces;Hardware;Safety;Software libraries;System recovery},
}

@Article{Flanagan02,
  author     = {Flanagan, Cormac and Qadeer, Shaz},
  title      = {Predicate Abstraction for Software Verification},
  journal    = {SIGPLAN Not.},
  year       = {2002},
  volume     = {37},
  number     = {1},
  pages      = {191--202},
  month      = jan,
  issn       = {0362-1340},
  acmid      = {503291},
  address    = {New York, NY, USA},
  issue_date = {Jan. 2002},
  numpages   = {12},
  publisher  = {ACM},
}

@InProceedings{Beyer17,
  author    = {Beyer, Dirk},
  title     = {Software Verification with Validation of Results},
  booktitle = {Proceedings, Part II, of the 23rd International Conference on Tools and Algorithms for the Construction and Analysis of Systems - Volume 10206},
  year      = {2017},
  pages     = {331--349},
  address   = {New York, NY, USA},
  publisher = {Springer-Verlag New York, Inc.},
  acmid     = {3080481},
  isbn      = {978-3-662-54579-9},
  numpages  = {19},
}

@InBook{Clarke20,
  pages     = {154--169},
  title     = {Counter\-example-Guided Abstraction Refinement},
  publisher = {Springer Berlin Heidelberg},
  year      = {2000},
  author    = {Clarke, Edmund and Grumberg, Orna and Jha, Somesh and Lu, Yuan and Veith, Helmut},
  editor    = {Emerson, E. Allen and Sistla, Aravinda Prasad},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-45047-4},
  abstract  = {We present an automatic iterative abstraction-refinement methodology in which the initial abstract model is generated by an automatic analysis of the control structures in the program to be verified. Abstract models may admit erroneous (or ``spurious'') counterexamples. We devise new symbolic techniques which analyze such counterexamples and refine the abstract model correspondingly. The refinement algorithm keeps the size of the abstract state space small due to the use of abstraction functions which distinguish many degrees of abstraction for each program variable. We describe an implementation of our methodology in NuSMV. Practical experiments including a large Fujitsu IP core design with about 500 latches and 10000 lines of SMV code confirm the effectiveness of our approach.},
  booktitle = {Computer Aided Verification: 12th International Conference, CAV 2000, Chicago, IL, USA, July 15-19, 2000. Proceedings},
}

@Online{svcomp,
  author  = {Dirk Beyer},
  title   = {SV-COMP Rules},
  year    = {2017},
  url     = {https://sv-comp.sosy-lab.org/2017/rules.php},
  urldate = {2017-12-02},
}

@InProceedings{SVCOMP2019,
    author="Beyer, Dirk",
    editor="Beyer, Dirk
    and Huisman, Marieke
    and Kordon, Fabrice
    and Steffen, Bernhard",
    title="Automatic Verification of C and Java Programs: SV-COMP 2019",
    booktitle="Tools and Algorithms for the Construction and Analysis of Systems",
    year="2019",
    publisher="Springer International Publishing",
    address="Cham",
    pages="133--155",
    abstract="This report describes the 2019 Competition on Software Verification (SV-COMP), the 8{\$}{\$}^{\{}{\backslash}text {\{}th{\}}{\}}{\$}{\$}edition of a series of comparative evaluations of fully automatic software verifiers for C programs, and now also for Java programs. The competition provides a snapshot of the current state of the art in the area, and has a strong focus on replicability of its results. The repository of benchmark verification tasks now supports a new, more flexible format for task definitions (based on YAML), which was a precondition for conveniently benchmarking Java programs in the same controlled competition setting that was successfully applied in the previous years. The competition was based on 10 522 verification tasks for C programs and 368 verification tasks for Java programs. Each verification task consisted of a program and a property (reachability, memory safety, overflows, termination). SV-COMP 2019 had 31 participating verification systems from 14 countries.",
    isbn="978-3-030-17502-3"
}

@Article{Jonas17,
  author        = {{Mr{\'a}zek}, Jan and {Jon{\'a}{\v s}}, Martin and {Barnat}, Ji{\v{r}}{\'i}},
  title         = {{SMT Queries Decomposition and Caching in Semi-Symbolic Model Checking}},
  journal       = {ArXiv e-prints},
  year          = {2017},
  month         = nov,
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {http://adsabs.harvard.edu/abs/2017arXiv171109084M},
  archiveprefix = {arXiv},
  eprint        = {1711.09084},
  keywords      = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
  primaryclass  = {cs.PL},
}

@InProceedings{Barrett2010,
  author    = {Barrett, Clark and Stump, Aaron and Tinelli, Cesare and others},
  title     = {The smt-lib standard: Version 2.0},
  booktitle = {Proceedings of the 8th International Workshop on Satisfiability Modulo Theories (Edinburgh, England)},
  year      = {2010},
  volume    = {13},
  pages     = {14},
}

@InCollection{Yang2008,
  author    = {Yang, Hongseok and Lee, Oukseh and Berdine, Josh and Calcagno, Cristiano and Cook, Byron and Distefano, Dino and O’Hearn, Peter},
  title     = {Scalable Shape Analysis for Systems Code},
  booktitle = {Computer Aided Verification},
  publisher = {Springer},
  year      = {2008},
  month     = jan,
  isbn      = {978-3-540-70543-7},
  abstract  = {Pointer safety faults in device drivers are one of the leading causes of crashes in operating systems code. In principle, shape analysis tools can be used to prove the absence of this type of error. In practice, however, shape analysis is not used due to the unacceptable mixture of scalability and precision provided by existing tools. In this paper we report on a new join operation ${\sqcup\dagger}$ for the separation domain which aggressively abstracts information for scalability yet does not lead to false error reports. ${\sqcup\dagger}$ is a critical piece of a new shape analysis tool that provides an acceptable mixture of scalability and precision for industrial application. Experiments on whole Windows and Linux device drivers (firewire, pci-driver, cdrom, md, etc.) represent the first working application of shape analysis to verification of whole industrial programs.},
  date      = {2008-01-01},
  doi       = {10.1007/978-3-540-70545-1_36},
  url       = {http://dx.doi.org/10.1007/978-3-540-70545-1_36},
}

@InProceedings{Henzinger2002,
  author    = {Henzinger, Thomas A. and Jhala, Ranjit and Majumdar, Rupak and Sutre, Gr{\'e}goire},
  title     = {Lazy Abstraction},
  booktitle = {Proceedings of the 29th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  year      = {2002},
  series    = {POPL '02},
  pages     = {58--70},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {503279},
  doi       = {10.1145/503272.503279},
  isbn      = {1-58113-450-9},
  location  = {Portland, Oregon},
  numpages  = {13},
  url       = {http://doi.acm.org/10.1145/503272.503279},
}

@InProceedings{Burch1990,
  author    = {J. R. {Burch} and E. M. {Clarke} and K. L. {McMillan} and D. L. {Dill} and L. J. {Hwang}},
  title     = {Symbolic model checking: 10\textsuperscript{20} states and beyond},
  booktitle = {Proc. Fifth Annual IEEE Symp. Logic in Computer Science [1990]},
  year      = {1990},
  pages     = {428--439},
  month     = jun,
  doi       = {10.1109/LICS.1990.113767},
  keywords  = {finite automata, specification languages, temporal logic, symbolic mu-calculus, iterative squaring transformation, PTL, binary decision diagrams, computation tree logic, mu-calculus, specification language, model-checking algorithm, binary decision diagrams, efficient decision procedures, CTL model checking, satisfiability, linear-time temporal logic formulas, observational equivalence, finite transition systems, language containment, finite omega -automata, complicated graph-traversal, nested fixed-point computations, decision procedure, symbolic model checking, synchronous pipeline, State-space methods, Data structures, Boolean functions, Logic testing, Explosions, Computer science, Pipelines, US Department of Defense, Contracts, Scholarships},
}

@Article{Majumdar2018,
  author    = {Majumdar, Rupak and Raskin, Jean-François},
  title     = {Symbolic Model Checking in Non-Boolean Domains},
  journal   = {Handbook of Model Checking},
  year      = {2018},
  month     = jan,
  abstract  = {We consider symbolic model checking as a general procedure to compute fixed points on general lattices. We show that this view provides a unified approach for formal reasoning about systems that is applicable to many different classes of systems and properties. Our unified view is based on the notion of region algebras together with appropriate generalizations of the modal μ$\mu$-calculus. We show applications of our general approach to problems in infinite-state verification, reactive synthesis, and the analysis of probabilistic systems.},
  date      = {2018-01-01},
  doi       = {10.1007/978-3-319-10575-8_31},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-319-10575-8_31},
}

@Article{Namjoshi2018,
  author    = {Namjoshi, Kedar S. and Pavlinovic, Zvonimir},
  title     = {The Impact of Program Transformations on Static Program Analysis},
  journal   = {Static Analysis},
  year      = {2018},
  month     = jan,
  abstract  = {Semantics-preserving program transformations, such as those carried out by an optimizing compiler, can affect the results of static program analyses. In the best cases, a transformation increases precision or allows a simpler analysis to replace a complex one. In other cases, transformations have the opposite effect, reducing precision. This work constructs a theoretical framework to analyze this intriguing phenomenon. The framework provides a simple, uniform explanation for precision changes, linking them to bisimulation relations that justify the correctness of a transformation. It offers a mechanism for recovering lost precision through the systematic construction of a new, bisimulating analysis. Furthermore, it is shown that program analyses defined over a class of composite domains can be factored into a program transformation followed by simpler, equally precise analyses of the target program.},
  date      = {2018-01-01},
  doi       = {10.1007/978-3-319-99725-4_19},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-319-99725-4_19},
}

@Article{Payet2018,
  author    = {Payet, Étienne and Spoto, Fausto},
  title     = {Checking Array Bounds by Abstract Interpretation and Symbolic Expressions},
  journal   = {Automated Reasoning},
  year      = {2018},
  month     = jan,
  abstract  = {Array access out of bounds is a typical programming error. From the ’70s, static analysis has been used to identify where such errors actually occur at runtime, through abstract interpretation into linear constraints. However, feasibility and scalability to modern object-oriented code has not been established yet. This article builds on previous work on linear constraints and shows that the result does not scale, when polyhedra implement the linear constraints, while the more abstract zones scale to the analysis of medium-size applications. Moreover, this article formalises the inclusion of symbolic expressions in the constraints and shows that this improves its precision. Expressions are automatically selected on-demand. The resulting analysis applies to code with dynamic memory allocation and arrays held in expressions. It is sound, also in the presence of arbitrary side-effects. It is fully defined in the abstract interpretation framework and does not use any code instrumentation. Its proof of correctness, its implementation inside the commercial Julia analyzer and experiments on third-party code complete the work.},
  date      = {2018-01-01},
  doi       = {10.1007/978-3-319-94205-6_46},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-319-94205-6_46},
}

@Article{Bakhirkin2017,
  author    = {Bakhirkin, Alexey and Monniaux, David},
  title     = {Combining Forward and Backward Abstract Interpretation of Horn Clauses},
  journal   = {Static Analysis},
  year      = {2017},
  month     = jan,
  abstract  = {Alternation of forward and backward analyses is a standard technique in abstract interpretation of programs, which is in particular useful when we wish to prove unreachability of some undesired program states. The current state-of-the-art technique for combining forward (bottom-up, in logic programming terms) and backward (top-down) abstract interpretation of Horn clauses is query-answer transformation. It transforms a system of Horn clauses, such that standard forward analysis can propagate constraints both forward, and backward from a goal. Query-answer transformation is effective, but has issues that we wish to address. For that, we introduce a new backward collecting semantics, which is suitable for alternating forward and backward abstract interpretation of Horn clauses. We show how the alternation can be used to prove unreachability of the goal and how every subsequent run of an analysis yields a refined model of the system. Experimentally, we observe that combining forward and backward analyses is important for analysing systems that encode questions about reachability in C programs. In particular, the combination that follows our new semantics improves the precision of our own abstract interpreter, including when compared to a forward analysis of a query-answer-transformed system.},
  date      = {2017-01-01},
  doi       = {10.1007/978-3-319-66706-5_2},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-319-66706-5_2},
}

@Article{Cousot2015,
  author    = {Cousot, Patrick},
  title     = {Abstracting Induction by Extrapolation and Interpolation},
  journal   = {Verification, Model Checking, and Abstract Interpretation},
  year      = {2015},
  month     = jan,
  abstract  = {We introduce a unified view of induction performed by automatic verification tools to prove a given program specification This unification is done in the abstract interpretation framework using extrapolation (widening/dual-widening) and interpolation (narrowing, dual-narrowing, which are equivalent up to the exchange of the parameters). Dual-narrowing generalizes Craig interpolation in First Order Logic pre-ordered by implication to arbitrary abstract domains. An increasing iterative static analysis using extrapolation of successive iterates by widening followed by a decreasing iterative static analysis using interpolation of successive iterates by narrowing (both bounded by the specification) can be further improved by a increasing iterative static analysis using interpolation of iterates with the specification by dual-narrowing until reaching a fixpoint and checking whether it is inductive for the specification.},
  date      = {2015-01-01},
  doi       = {10.1007/978-3-662-46081-8_2},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-662-46081-8_2},
}

@Article{Chen2015,
  author    = {Chen, Junjie and Cousot, Patrick},
  title     = {A Binary Decision Tree Abstract Domain Functor},
  journal   = {Static Analysis},
  year      = {2015},
  month     = jan,
  abstract  = {We present an abstract domain functor whose elements are binary decision trees. It is parameterized by decision nodes which are a set of boolean tests appearing in the programs and by a numerical or symbolic abstract domain whose elements are the leaves. We first define the branch condition path abstraction which forms the decision nodes of the binary decision trees. It also provides a new prospective on partitioning the trace semantics of programs as well as separating properties in the leaves. We then discuss our binary decision tree abstract domain functor by giving algorithms for inclusion test, meet and join, transfer functions and extrapolation operators. We think the binary decision tree abstract domain functor may provide a flexible way of adjusting the cost/precision ratio in path-dependent static analysis.},
  date      = {2015-01-01},
  doi       = {10.1007/978-3-662-48288-9_3},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-662-48288-9_3},
}

@Article{Cousot2012,
  author    = {Cousot, Patrick},
  title     = {Formal Verification by Abstract Interpretation},
  journal   = {NASA Formal Methods},
  year      = {2012},
  month     = jan,
  abstract  = {We provide a rapid overview of the theoretical foundations and main applications of abstract interpretation and show that it currently provides scaling solutions to achieving assurance in mission- and safety-critical systems through verification by fully automatic, semantically sound and precise static program analysis.},
  date      = {2012-01-01},
  doi       = {10.1007/978-3-642-28891-3_3},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-642-28891-3_3},
}

@Article{Cousot2012a,
  author    = {Cousot, Patrick and Monerau, Michael},
  title     = {Probabilistic Abstract Interpretation},
  journal   = {Programming Languages and Systems},
  year      = {2012},
  month     = jan,
  abstract  = {Abstract interpretation has been widely used for verifying properties of computer systems. Here, we present a way to extend this framework to the case of probabilistic systems.The probabilistic abstraction framework that we propose allows us to systematically lift any classical analysis or verification method to the probabilistic setting by separating in the program semantics the probabilistic behavior from the (non-)deterministic behavior. This separation provides new insights for designing novel probabilistic static analyses and verification methods.We define the concrete probabilistic semantics and propose different ways to abstract them. We provide examples illustrating the expressiveness and effectiveness of our approach.},
  date      = {2012-01-01},
  doi       = {10.1007/978-3-642-28869-2_9},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-642-28869-2_9},
}

@Article{Cousot2011,
  author    = {Cousot, Patrick and Cousot, Radhia and Mauborgne, Laurent},
  title     = {Logical Abstract Domains and Interpretations},
  journal   = {The Future of Software Engineering},
  year      = {2011},
  month     = jan,
  abstract  = {We give semantic foundations to abstract domains consisting in first order logic formulæ in a theory, as used in verification tools or methods using SMT-solvers or theorem provers.We exhibit conditions for a sound usage of such methods with respect to multi-interpreted semantics and extend their usage to automatic invariant generation by abstract interpretation.},
  date      = {2011-01-01},
  doi       = {10.1007/978-3-642-15187-3_3},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-642-15187-3_3},
}

@Article{Chen2008,
  author    = {Chen, Liqian and Miné, Antoine and Cousot, Patrick},
  title     = {A Sound Floating-Point Polyhedra Abstract Domain},
  journal   = {Programming Languages and Systems},
  year      = {2008},
  month     = jan,
  abstract  = {The polyhedra abstract domain is one of the most powerful and commonly used numerical abstract domains in the field of static program analysis based on abstract interpretation. In this paper, we present an implementation of the polyhedra domain using floating-point arithmetic without sacrificing soundness. Floating-point arithmetic allows a compact memory representation and an efficient implementation on current hardware, at the cost of some loss of precision due to rounding. Our domain is based on a constraint-only representation and employs sound floating-point variants of Fourier-Motzkin elimination and linear programming. The preliminary experimental results of our prototype are encouraging. To our knowledge, this is the first time that the polyhedra domain is adapted to floating-point arithmetic in a sound way.},
  date      = {2008-01-01},
  doi       = {10.1007/978-3-540-89330-1_2},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-540-89330-1_2},
}

@InProceedings{Cousot2015a,
  author    = {P. {Cousot}},
  title     = {On Various Abstract Understandings of Abstract Interpretation},
  booktitle = {Proc. Int. Symp. Theoretical Aspects of Software Engineering},
  year      = {2015},
  pages     = {2--3},
  month     = sep,
  doi       = {10.1109/TASE.2015.29},
  keywords  = {program diagnostics, abstract understanding, abstract interpretation theory, Semantics, Computer languages, Concrete, Interpolation, Presses, Extrapolation, Abstract Interpretation, Abstraction, Completeness, Formal methods, Semantics, Semantics, Soundness, Static analysis, Verification},
}

@Article{Beyer2018,
  author    = {Beyer, Dirk and Dangl, Matthias and Wendler, Philipp},
  title     = {A Unifying View on SMT-Based Software Verification},
  journal   = {Journal of Automated Reasoning},
  year      = {2018},
  volume    = {60},
  number    = {3},
  pages     = {299},
  month     = mar,
  issn      = {1573-0670},
  abstract  = {After many years of successful development of new approaches for software verification, there is a need to consolidate the knowledge about the different abstract domains and algorithms. The goal of this paper is to provide a compact and accessible presentation of four SMT-based verification approaches in order to study them in theory and in practice. We present and compare the following different “schools of thought” of software verification: bounded model checking, k-induction, predicate abstraction, and lazy abstraction with interpolants. Those approaches are well-known and successful in software verification and have in common that they are based on SMT solving as the back-end technology. We reformulate all four approaches in the unifying theoretical framework of configurable program analysis and implement them in the verification framework CPAchecker. Based on this, we can present an evaluation that thoroughly compares the different approaches, where the core differences are expressed in configuration parameters and all other variables are kept constant (such as parser front end, SMT solver, used theory in SMT formulas). We evaluate the effectiveness and the efficiency of the approaches on a large set of verification tasks and discuss the conclusions.},
  date      = {2018-03-01},
  doi       = {10.1007/s10817-017-9432-6},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/s10817-017-9432-6},
}

@Article{Beyer2018b,
  author    = {Beyer, Dirk and Gulwani, Sumit and Schmidt, David A.},
  title     = {Combining Model Checking and Data-Flow Analysis},
  journal   = {Handbook of Model Checking},
  year      = {2018},
  month     = jan,
  abstract  = {Until recently, model checking and data-flow analysis—two traditional approaches to software verification—were used independently and in isolation for solving similar problems. Theoretically, the two different approaches are equivalent; they are two different ways to compute the same solution to a problem. In recent years, new practical approaches have shown how to combine the approaches and how to make them benefit from each other—model-checking techniques can make data-flow analyses more precise, and data-flow-analysis techniques can make model checking more efficient. This chapter starts by discussing the relationship (differences and similarities) between type checking, data-flow analysis, and model checking. Then we define algorithms for data-flow analysis and model checking in the same formal setting, called configurable program analysis. This identifies key differences that make us call an algorithm a “model-checking” algorithm or a “data-flow-analysis” algorithm. We illustrate the effect of using different algorithms for running certain classic example analyses and point out the reason for one algorithm being “better” than the other. The chapter presents combined verification techniques in the framework of configurable program analysis, in order to emphasize techniques used in data-flow analysis and in model checking. Besides the iterative algorithm that is used to illustrate the similarities and differences between data-flow analysis and model checking, we discuss different algorithmic approaches for constructing program invariants. To show that the border between data-flow analysis and model checking is blurring and disappearing, we also discuss directions in tool implementations for combined verification approaches.},
  date      = {2018-01-01},
  doi       = {10.1007/978-3-319-10575-8_16},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-319-10575-8_16},
}

@Article{Beyer2018e,
  author    = {Beyer, Dirk and Friedberger, Karlheinz},
  title     = {In-Place vs. Copy-on-Write CEGAR Refinement for Block Summarization with Caching},
  journal   = {Leveraging Applications of Formal Methods, Verification and Validation. Verification},
  year      = {2018},
  month     = jan,
  abstract  = {Block summarization is an efficient technique in software verification to decompose a verification problem into separate tasks and to avoid repeated exploration of reusable parts of a program. In order to benefit from abstraction at the same time, block summarization can be combined with counterexample-guided abstraction refinement (CEGAR). This causes the following problem: whenever CEGAR instructs the model checker to refine the abstraction along a path, several block summaries are affected and need to be updated. There exist two different refinement strategies: a destructive in-place approach that modifies the existing block abstractions and a constructive copy-on-write approach that does not change existing data. While the in-place approach is used in the field for several years, our new approach of copy-on-write refinement has the following important advantage: A complete exportable proof of the program is available after the analysis has finished. Due to the benefit from avoiding recomputations of missing information as necessary for in-place updates, the new approach causes almost no computational overhead overall. We perform a large experimental evaluation to compare the new approach with the previous one to show that full proofs can be achieved without overhead.},
  date      = {2018-01-01},
  doi       = {10.1007/978-3-030-03421-4_14},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-030-03421-4_14},
}

@Article{Beyer2016,
  author    = {Beyer, Dirk and Lemberger, Thomas},
  title     = {Symbolic Execution with CEGAR},
  journal   = {Leveraging Applications of Formal Methods, Verification and Validation: Foundational Techniques},
  year      = {2016},
  month     = jan,
  abstract  = {Symbolic execution, a standard technique in program analysis, is a particularly successful and popular component in systems for test-case generation. One of the open research problems is that the approach suffers from the path-explosion problem. We apply abstraction to symbolic execution, and refine the abstract model using counterexample-guided abstraction refinement (Cegar), a standard technique from model checking. We also use refinement selection with existing and new heuristics to influence the behavior and further improve the performance of our refinement procedure. We implemented our new technique in the open-source software-verification framework CPAchecker. Our experimental results show that the implementation is highly competitive.},
  date      = {2016-01-01},
  doi       = {10.1007/978-3-319-47166-2_14},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-319-47166-2_14},
}

@Article{Beyer2016c,
  author    = {Beyer, Dirk and Dangl, Matthias},
  title     = {SMT-based Software Model Checking: An Experimental Comparison of Four Algorithms},
  journal   = {Verified Software. Theories, Tools, and Experiments},
  year      = {2016},
  month     = jan,
  abstract  = {After many years of successful development of new algorithms for software model checking, there is a need to consolidate the knowledge about the different algorithms and approaches. This paper gives a coarse overview in terms of effectiveness and efficiency of four algorithms. We compare the following different “schools of thought” of algorithms: bounded model checking, k-induction, predicate abstraction, and lazy abstraction with interpolants. Those algorithms are well-known and successful in software verification. They have in common that they are based on SMT solving as the back-end technology, using the theories of uninterpreted functions, bit vectors, and floats as underlying theory. All four algorithms are implemented in the verification framework CPAchecker. Thus, we can present an evaluation that really compares only the core algorithms, and keeps the design variables such as parser front end, SMT solver, used theory in SMT formulas, etc. constant. We evaluate the algorithms on a large set of verification tasks, and discuss the conclusions.},
  date      = {2016-01-01},
  doi       = {10.1007/978-3-319-48869-1_14},
  publisher = {Springer},
  url       = {http://dx.doi.org/10.1007/978-3-319-48869-1_14},
}

@InCollection{Beyer2007,
  author    = {Beyer, Dirk and Henzinger, Thomas A. and Théoduloz, Grégory},
  title     = {Configurable Software Verification: Concretizing the Convergence of Model Checking and Program Analysis},
  booktitle = {Computer Aided Verification},
  publisher = {Springer},
  year      = {2007},
  month     = jan,
  isbn      = {978-3-540-73367-6},
  abstract  = {In automatic software verification, we have observed a theoretical convergence of model checking and program analysis. In practice, however, model checkers are still mostly concerned with precision, e.g., the removal of spurious counterexamples; for this purpose they build and refine reachability trees. Lattice-based program analyzers, on the other hand, are primarily concerned with efficiency. We designed an algorithm and built a tool that can be configured to perform not only a purely tree-based or a purely lattice-based analysis, but offers many intermediate settings that have not been evaluated before. The algorithm and tool take one or more abstract interpreters, such as a predicate abstraction and a shape analysis, and configure their execution and interaction using several parameters. Our experiments show that such customization may lead to dramatic improvements in the precision-efficiency spectrum.},
  date      = {2007-01-01},
  doi       = {10.1007/978-3-540-73368-3_51},
  url       = {http://dx.doi.org/10.1007/978-3-540-73368-3_51},
}

@InCollection{Beyer2006a,
  author    = {Beyer, Dirk and Henzinger, Thomas A. and Théoduloz, Grégory},
  title     = {Lazy Shape Analysis},
  booktitle = {Computer Aided Verification},
  publisher = {Springer},
  year      = {2006},
  month     = jan,
  isbn      = {978-3-540-37406-0},
  abstract  = {Many software model checkers are based on predicate abstraction. If the verification goal depends on pointer structures, the approach does not work well, because it is difficult to find adequate predicate abstractions for the heap. In contrast, shape analysis, which uses graph-based heap abstractions, can provide a compact representation of recursive data structures. We integrate shape analysis into the software model checker Blast. Because shape analysis is expensive, we do not apply it globally. Instead, we ensure that, like predicates, shape graphs are computed and stored locally, only where necessary for proving the verification goal. To achieve this, we extend lazy abstraction refinement, which so far has been used only for predicate abstractions, to three-valued logical structures. This approach does not only increase the precision of model checking, but it also increases the efficiency of shape analysis. We implemented the technique by extending Blast with calls to Tvla.},
  date      = {2006-01-01},
  doi       = {10.1007/11817963_48},
  url       = {http://dx.doi.org/10.1007/11817963_48},
}

@InProceedings{Cousot1977,
  author    = {Cousot, Patrick and Cousot, Radhia},
  title     = {Abstract Interpretation: A Unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixpoints},
  booktitle = {Proceedings of the 4th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
  year      = {1977},
  series    = {POPL '77},
  pages     = {238--252},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {512973},
  doi       = {10.1145/512950.512973},
  location  = {Los Angeles, California},
  numpages  = {15},
  url       = {http://doi.acm.org/10.1145/512950.512973},
}

@InProceedings{Cousot1979,
  author    = {Cousot, Patrick and Cousot, Radhia},
  title     = {Systematic Design of Program Analysis Frameworks},
  booktitle = {Proceedings of the 6th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
  year      = {1979},
  series    = {POPL '79},
  pages     = {269--282},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {567778},
  doi       = {10.1145/567752.567778},
  location  = {San Antonio, Texas},
  numpages  = {14},
  url       = {http://doi.acm.org/10.1145/567752.567778},
}

@Article{Cousot1992,
  author     = {Cousot, Patrick and Cousot, Rahida},
  title      = {Abstract Interpretation and Application to Logic Programs},
  journal    = {J. Log. Program.},
  year       = {1992},
  volume     = {13},
  number     = {2-3},
  pages      = {103--179},
  month      = jul,
  issn       = {0743-1066},
  acmid      = {140970},
  address    = {New York, NY, USA},
  doi        = {10.1016/0743-1066(92)90030-7},
  issue_date = {July 1992},
  numpages   = {77},
  publisher  = {Elsevier Science Inc.},
  url        = {http://dx.doi.org/10.1016/0743-1066(92)90030-7},
}

@Article{Cousot1992b,
  author    = {Cousot, P{.} and Cousot, R{.}},
  title     = {Abstract Interpretation Frameworks},
  journal   = {Journal of Logic and Computation},
  year      = {1992},
  volume    = {2},
  number    = {4},
  pages     = {511--547},
  month     = auf,
  publisher = {Oxford University Press, Oxford, UK},
}

@InProceedings{Cousot1992a,
  author    = {Cousot, Patrick and Cousot, Radhia},
  title     = {Comparing the Galois Connection and Widening/Narrowing Approaches to Abstract Interpretation},
  booktitle = {Proceedings of the 4th International Symposium on Programming Language Implementation and Logic Programming},
  year      = {1992},
  series    = {PLILP '92},
  pages     = {269--295},
  address   = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid     = {692441},
  isbn      = {3-540-55844-6},
  numpages  = {27},
  url       = {http://dl.acm.org/citation.cfm?id=646448.692441},
}

@Article{Cortesi1995,
  author        = {Cortesi, Agostino and Filé, Gilberto and Giacobazzi, Roberto and Palamidessi, Catuscia and Ranzato, Francesco},
  title         = {Complementation in abstract interpretation},
  journal       = {Static Analysis},
  year          = {1995},
  month         = jan,
  __markedentry = {[heno:]},
  abstract      = {The reduced product of abstract domains is a rather well known operation in abstract interpretation. In this paper we study the inverse operation, which we call complementation. Such an operation allows to systematically decompose domains; it provides a systematic way to design new abstract domains; it allows to simplify domain verification problems, like correctness proofs; and it yields space saving representations for domains. We show that the complement exists in most cases, and we apply complementation to two well known abstract domains, notably to the Cousot and Cousot's comportment domain for analysis of functional languages and to the complex domain Sharing for aliasing analysis of logic languages.},
  date          = {1995-01-01},
  doi           = {10.1007/3-540-60360-3_35},
  publisher     = {Springer},
  url           = {http://dx.doi.org/10.1007/3-540-60360-3_35},
}

@Book{Birkhoff1940,
  title     = {Lattice Theory},
  publisher = {American Mathematical Society},
  year      = {1940},
  author    = {Birkhoff, G.},
  number    = {v. 25, pt. 2},
  series    = {American Mathematical Society colloquium publications},
  isbn      = {9780821810255},
  lccn      = {66023707},
  url       = {https://books.google.cz/books?id=ePqVAwAAQBAJ},
}

@Article{arski1955,
  author    = {Tarski, Alfred},
  title     = {A lattice-theoretical fixpoint theorem and its applications.},
  journal   = {Pacific J. Math.},
  year      = {1955},
  volume    = {5},
  number    = {2},
  pages     = {285--309},
  fjournal  = {Pacific Journal of Mathematics},
  publisher = {Pacific Journal of Mathematics, A Non-profit Corporation},
  url       = {https://projecteuclid.org:443/euclid.pjm/1103044538},
}

@InProceedings{Kildall1973,
  author    = {Kildall, Gary A.},
  title     = {A Unified Approach to Global Program Optimization},
  booktitle = {Proceedings of the 1st Annual ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
  year      = {1973},
  series    = {POPL '73},
  pages     = {194--206},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {512945},
  doi       = {10.1145/512927.512945},
  location  = {Boston, Massachusetts},
  numpages  = {13},
  url       = {http://doi.acm.org/10.1145/512927.512945},
}

@Article{Tarski1955,
  author    = {Tarski, Alfred},
  title     = {A lattice-theoretical fixpoint theorem and its applications.},
  journal   = {Pacific J. Math.},
  year      = {1955},
  volume    = {5},
  number    = {2},
  pages     = {285--309},
  fjournal  = {Pacific Journal of Mathematics},
  publisher = {Pacific Journal of Mathematics, A Non-profit Corporation},
  url       = {https://projecteuclid.org:443/euclid.pjm/1103044538},
}

@Article{Mine2006,
  author        = {Miné, Antoine},
  title         = {The octagon abstract domain},
  journal       = {Higher-Order and Symbolic Computation},
  year          = {2006},
  volume        = {19},
  number        = {1},
  pages         = {31},
  month         = mar,
  __markedentry = {[heno:6]},
  abstract      = {This article presents the octagon abstract domain, a relational numerical abstract domain for static analysis by abstract interpretation. It allows representing conjunctions of constraints of the form ± X ± Y ≤ c where X and Y range among program variables and c is a constant in ℤ, ℚ, or ℝ automatically inferred. Abstract elements are represented using modified Difference Bound Matrices and we use a normalization algorithm loosely based on the shortest-path closure to compute canonical representations and construct best-precision abstract transfer functions. We achieve a quadratic memory cost per abstract element and a cubic worst-case time cost per abstract operation, with respect to the number of program variables.In terms of cost and precision, our domain is in between the well-known fast but imprecise interval domain and the costly polyhedron domain. We show that it is precise enough to treat interesting examples requiring relational invariants, and hence, out of the reach of the interval domain. We also present a packing strategy that allows scaling our domain up to large programs by tuning the amount of relationality. The octagon domain was incorporated into the ASTRÉE industrial-strength static analyzer and was key in proving the absence of run-time errors in large critical embedded flight control software for Airbus planes.},
  date          = {2006-03-01},
  doi           = {10.1007/s10990-006-8609-1},
  publisher     = {Springer},
  url           = {http://dx.doi.org/10.1007/s10990-006-8609-1},
}

@InCollection{Mine2002,
  author        = {Miné, Antoine},
  title         = {A Few Graph-Based Relational Numerical Abstract Domains},
  booktitle     = {Static Analysis},
  publisher     = {Springer},
  year          = {2002},
  month         = jan,
  isbn          = {978-3-540-44235-6},
  __markedentry = {[heno:6]},
  abstract      = {This article presents the systematic design of a class of relational numerical abstract domains from non-relational ones. Constructed domains represent sets of invariants of the form (vj - vi∈ C), where vj and vi are two variables, and C lives in an abstraction of $$
\mathcal{P}(\mathbb{Z})
$$
, $$
\mathcal{P}(\mathbb{Q})
$$
, or $$
\mathcal{P}(\mathbb{R})
$$
. We will call this family of domains weakly relational domains. The underlying concept allowing this construction is an extension of potential graphs and shortest-path closure algorithms in exotic-like algebras. Example constructions are given in order to retrieve well-known domains as well as new ones. Such domains can then be used in the Abstract Interpretation framework in order to design various static analyses. A major benefit of this construction is its modularity, allowing to quickly implement new abstract domains from existing ones.},
  date          = {2002-01-01},
  doi           = {10.1007/3-540-45789-5_11},
  url           = {http://dx.doi.org/10.1007/3-540-45789-5_11},
}

@InCollection{Granger1991,
  author        = {Granger, Philippe},
  title         = {Static analysis of linear congruence equalities among variables of a program},
  booktitle     = {TAPSOFT '91},
  publisher     = {Springer},
  year          = {1991},
  month         = jan,
  isbn          = {978-3-540-53982-7},
  __markedentry = {[heno:6]},
  abstract      = {This paper is dedicated to the presentation of a new static analysis of programs conceived for discovering linear congruence equations satisfied by integer valued variables (or more generally by any set of integer values abstracted from a program). This analysis generalizes both P. Granger's arithmetical congruence analysis and M. Karr's affine equation analysis. An example shows that it can provide valuable results for automatic vectorization.},
  date          = {1991-01-01},
  doi           = {10.1007/3-540-53982-4_10},
  url           = {http://dx.doi.org/10.1007/3-540-53982-4_10},
}

@Article{Granger1989,
  author    = {Philippe Granger},
  title     = {Static analysis of arithmetical congruences},
  journal   = {International Journal of Computer Mathematics},
  year      = {1989},
  volume    = {30},
  number    = {3-4},
  pages     = {165-190},
  doi       = {10.1080/00207168908803778},
  eprint    = {https://doi.org/10.1080/00207168908803778},
  publisher = {Taylor \& Francis},
  url       = { 
        https://doi.org/10.1080/00207168908803778
    
},
}

@Article{Cortesi2011,
  author  = {Cortesi, Agostino and Zanioli, Matteo},
  title   = {Widening and narrowing operators for abstract interpretation},
  journal = {Computer Languages, Systems \& Structures},
  year    = {2011},
  volume  = {37},
  pages   = {24-42},
  month   = {04},
  doi     = {10.1016/j.cl.2010.09.001},
}

@InProceedings{Lakhdar2011,
  author    = {Lakhdar-Chaouch, 1Lies and Jeannet, Bertrand and Girault, Alain},
  title     = {Widening with Thresholds for Programs with Complex Control Graphs},
  booktitle = {Automated Technology for Verification and Analysis},
  year      = {2011},
  editor    = {Bultan, Tevfik and Hsiung, Pao-Ann},
  pages     = {492--502},
  address   = {Berlin, Heidelberg},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {The precision of an analysis based on abstract interpretation does not only depend on the abstract domain, but also on the solving method. The traditional solution is to solve iteratively abstract fixpoint equations, using extrapolation with a widening operator to make the iterations converge. Unfortunately, this extrapolation often loses crucial information for the analysis goal. A classical technique for improving the precision is ``widening with thresholds'', which bounds the extrapolation. Its benefit strongly depends on the choice of relevant thresholds. In this paper we propose a semantic-based technique for automatically inferring such thresholds, which applies to any control graph, be it intraprocedural, interprocedural or concurrent, without specific assumptions on the abstract domain. Despite its technical simplicity, our technique is able to infer the relevant thresholds in many practical cases.},
  isbn      = {978-3-642-24372-1},
}

@Article{Bagnara2008,
  author   = {Roberto Bagnara and Patricia M. Hill and Elisa Ricci and Enea Zaffanella},
  title    = {Precise widening operators for convex polyhedra},
  journal  = {Science of Computer Programming},
  year     = {2005},
  volume   = {58},
  number   = {1},
  pages    = {28 - 56},
  issn     = {0167-6423},
  note     = {Special Issue on the Static Analysis Symposium 2003},
  abstract = {In the context of static analysis via abstract interpretation, convex polyhedra constitute the most used abstract domain among those capturing numerical relational information. Since the domain of convex polyhedra admits infinite ascending chains, it has to be used in conjunction with appropriate mechanisms for enforcing and accelerating the convergence of fixpoint computations. Widening operators provide a simple and general characterization for such mechanisms. For the domain of convex polyhedra, the original widening operator proposed by Cousot and Halbwachs amply deserves the name of standard widening since most analysis and verification tools that employ convex polyhedra also employ that operator. Nonetheless, there is an unfulfilled demand for more precise widening operators. In this paper, after a formal introduction to the standard widening where we clarify some aspects that are often overlooked, we embark on the challenging task of improving on it. We present a framework for the systematic definition of new widening operators that are never less precise than a given widening. The framework is then instantiated on the domain of convex polyhedra so as to obtain a new widening operator that improves on the standard widening by combining several heuristics. A preliminary experimental evaluation has yielded promising results. We also suggest an improvement to the well-known widening delay technique that allows one to gain precision while preserving its overall simplicity.},
  doi      = {https://doi.org/10.1016/j.scico.2005.02.003},
  keywords = {Abstract interpretation, Widening operators, Convex polyhedra},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642305000432},
}

@Article{Blanchet2003,
  author     = {Blanchet, Bruno and Cousot, Patrick and Cousot, Radhia and Feret, J{\'e}rome and Mauborgne, Laurent and Min{\'e}, Antoine and Monniaux, David and Rival, Xavier},
  title      = {A Static Analyzer for Large Safety-critical Software},
  journal    = {SIGPLAN Not.},
  year       = {2003},
  volume     = {38},
  number     = {5},
  pages      = {196--207},
  month      = may,
  issn       = {0362-1340},
  acmid      = {781153},
  address    = {New York, NY, USA},
  doi        = {10.1145/780822.781153},
  issue_date = {May 2003},
  keywords   = {abstract domains, abstract interpretation, embedded, floating point, reactive, real-time, safety-critical software, static analysis, verification},
  numpages   = {12},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/780822.781153},
}

@InProceedings{Gonnord2006,
  author    = {Gonnord, Laure and Halbwachs, Nicolas},
  title     = {Combining Widening and Acceleration in Linear Relation Analysis},
  booktitle = {Static Analysis},
  year      = {2006},
  editor    = {Yi, Kwangkeun},
  pages     = {144--160},
  address   = {Berlin, Heidelberg},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Linear Relation Analysis [CH78, Hal79] is one of the first, but still one of the most powerful, abstract interpretations working in an infinite lattice. As such, it makes use of a widening operator to enforce the convergence of fixpoint computations. While the approximation due to widening can be arbitrarily refined by delaying the application of widening, the analysis quickly becomes too expensive with the increase of delay. Previous attempts at improving the precision of widening are not completely satisfactory, since none of them is guaranteed to improve the precision of the result, and they can nevertheless increase the cost of the analysis. In this paper, we investigate an improvement of Linear Relation Analysis consisting in computing, when possible, the exact (abstract) effect of a loop. This technique is fully compatible with the use of widening, and whenever it applies, it improves both the precision and the performance of the analysis.},
  isbn      = {978-3-540-37758-0},
}

@Article{Feautrier2010,
  author   = {Paul Feautrier and Laure Gonnord},
  title    = {Accelerated Invariant Generation for C Programs with Aspic and C2fsm},
  journal  = {Electronic Notes in Theoretical Computer Science},
  year     = {2010},
  volume   = {267},
  number   = {2},
  pages    = {3 - 13},
  issn     = {1571-0661},
  note     = {Proceedings of the Tools for Automatic Program AnalysiS (TAPAS)},
  abstract = {In this paper, we present Aspic, an automatic polyhedral invariant generation tool for flowcharts programs. Aspic implements an improved Linear Relation Analysis on numeric counter automata. The “accelerated” method improves precision by computing locally a precise overapproximation of a loop without using the widening operator. c2fsm is a C preprocessor that generates automata in the format required by Aspic. The experimental results show the performance and precision of the tools.},
  doi      = {https://doi.org/10.1016/j.entcs.2010.09.014},
  keywords = {Abstract interpretation, polyhedral abstract domain, acceleration, fixpoint iteration, flowchat programs, compilation, tools},
  url      = {http://www.sciencedirect.com/science/article/pii/S157106611000143X},
}

@InProceedings{Costan2005,
  author    = {Costan, A. and Gaubert, S. and Goubault, E. and Martel, M. and Putot, S.},
  title     = {A Policy Iteration Algorithm for Computing Fixed Points in Static Analysis of Programs},
  booktitle = {Computer Aided Verification},
  year      = {2005},
  editor    = {Etessami, Kousha and Rajamani, Sriram K.},
  pages     = {462--475},
  address   = {Berlin, Heidelberg},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {We present a new method for solving the fixed point equations that appear in the static analysis of programs by abstract interpretation. We introduce and analyze a policy iteration algorithm for monotone self-maps of complete lattices. We apply this algorithm to the particular case of lattices arising in the interval abstraction of values of variables. We demonstrate the improvements in terms of speed and precision over existing techniques based on Kleene iteration, including traditional widening/narrowing acceleration mecanisms.},
  isbn      = {978-3-540-31686-2},
}

@InProceedings{Gaubert2007,
  author    = {Gaubert, Stephane and Goubault, Eric and Taly, Ankur and Zennou, Sarah},
  title     = {Static Analysis by Policy Iteration on Relational Domains},
  booktitle = {Programming Languages and Systems},
  year      = {2007},
  editor    = {De Nicola, Rocco},
  pages     = {237--252},
  address   = {Berlin, Heidelberg},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {We give a new practical algorithm to compute, in finite time, a fixpoint (and often the least fixpoint) of a system of equations in the abstract numerical domains of zones and templates used for static analysis of programs by abstract interpretation. This paper extends previous work on the non-relational domain of intervals to relational domains. The algorithm is based on policy iteration techniques-- rather than Kleene iterations as used classically in static analysis-- and generates from the system of equations a finite set of simpler systems that we call policies. This set of policies satisfies a selection property which ensures that the minimal fixpoint of the original system of equations is the minimum of the fixpoints of the policies. Computing a fixpoint of a policy is done by linear programming. It is shown, through experiments made on a prototype analyzer, compared in particular to analyzers such as LPInv or the Octagon Analyzer, to be in general more precise and faster than the usual Kleene iteration combined with widening and narrowing techniques.},
  isbn      = {978-3-540-71316-6},
}

@InProceedings{Gawlitza2007,
  author    = {Gawlitza, Thomas and Seidl, Helmut},
  title     = {Precise Fixpoint Computation Through Strategy Iteration},
  booktitle = {Programming Languages and Systems},
  year      = {2007},
  editor    = {De Nicola, Rocco},
  pages     = {300--315},
  address   = {Berlin, Heidelberg},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {We present a practical algorithm for computing least solutions of systems of equations over the integers with addition, multiplication with positive constants, maximum and minimum. The algorithm is based on strategy iteration. Its run-time (w.r.t. the uniform cost measure) is independent of the sizes of occurring numbers. We apply our technique to solve systems of interval equations. In particular, we show how arbitrary intersections as well as full interval multiplication in interval equations can be dealt with precisely.},
  isbn      = {978-3-540-71316-6},
}

@InProceedings{Gawlitza2007b,
  author    = {Gawlitza, Thomas and Seidl, Helmut},
  title     = {Precise Relational Invariants Through Strategy Iteration},
  booktitle = {Computer Science Logic},
  year      = {2007},
  editor    = {Duparc, Jacques and Henzinger, Thomas A.},
  pages     = {23--40},
  address   = {Berlin, Heidelberg},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {We present a practical algorithm for computing exact least solutions of systems of equations over the rationals with addition, multiplication with positive constants, minimum and maximum. The algorithm is based on strategy improvement combined with solving linear programming problems for each selected strategy. We apply our technique to compute the abstract least fixpoint semantics of affine programs over the relational template constraint matrix domain [20]. In particular, we thus obtain practical algorithms for computing the abstract least fixpoint semantics over the zone and octagon abstract domain.},
  isbn      = {978-3-540-74915-8},
}

@Article{Gawlitza2011,
  author     = {Gawlitza, Thomas Martin and Seidl, Helmut},
  title      = {Solving Systems of Rational Equations Through Strategy Iteration},
  journal    = {ACM Trans. Program. Lang. Syst.},
  year       = {2011},
  volume     = {33},
  number     = {3},
  pages      = {11:1--11:48},
  month      = may,
  issn       = {0164-0925},
  acmid      = {1961207},
  address    = {New York, NY, USA},
  articleno  = {11},
  doi        = {10.1145/1961204.1961207},
  issue_date = {April 2011},
  keywords   = {Static program analysis, abstract interpretation, fixpoint equation systems, recursive stochastic games, strategy improvement algorithms},
  numpages   = {48},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/1961204.1961207},
}

@Comment{jabref-meta: databaseType:bibtex;}
