\chapter{Aims of the thesis}
\label{ch:aim}

% Stanovení cílů a metodologie disertační práce ("co, proč, jak"), očekávané výsledky, dosažené výsledky, časový harmonogram dalšího postupu, alespoň 2 strany.

Generally, techniques presented in the previous chapter are implemented as
dynamic analysis (i.e. the abstraction is performed on the fly inside of the
program interpreter).  In my research I focus on the development of
repurposable abstraction techniques. To achieve this, we need to extract
abstraction out of the tools and redesign the algorithms to provide sufficient
information for the program analysis. The similar shifting of responsibilities
is already known technique in computer science -- an example are compiled and
interpreted languages, that shifts various tasks between compilation time and
actual run time. In my work, I investigate how much it is possible to move
abstraction from the interpreter to the compilation. Naturally, there exist
many possible boundaries between abstraction and execution engine -- each
defined by how much of the actual abstract interpretation is performed by the
program or executor (see \autoref{fig:bounds}).

As listed in \autoref{sec:ingredients} the abstract domain is determined by
three components (value representation, operators, and iteration strategy).
Each of these components can be positioned on a different side of the boundary.

The typical approach in abstract interpreters is to keep all of them inside of
the interpreter. However, we can let the program to maintain abstract data and
instrument abstract operations into the program (realize them as a concrete
code). Therefore the execution engine will be only responsible for iteration
strategy and refinement.

To minimize the loss of precision, we usually only want to abstract
nondeterministic data of the program. Hence the analysis needs to decide which
operations will be abstracted. Another possibility is to dynamically determine
whether to perform an abstract or concrete operation. This decision can also be
moved between the program under analysis and execution engine. Usually, to
perform such a decision, the engine keeps track of additional metadata
associated with the values, which will determine whether the value is concrete
or not.

Another part of abstraction execution is a decision procedure which determines
the feasibility of a program path. One can argue that it can also be extracted
out of the execution engine for our purpose.

\begin{figure}[h]
%    \begin{minipage}[t]{0.45\textwidth}
%        pure program + abstract interpreter
%    \begin{tikzpicture}
%    \end{tikzpicture}
%    \end{minipage}
%    \hfill
%    \begin{minipage}[t]{0.45\textwidth}
%        program with abstract data + interpreter with metadata
%    \begin{tikzpicture}
%    \end{tikzpicture}
%    \end{minipage}

%    \begin{minipage}[t]{0.45\textwidth}
%        program with abstract data and metadata + concrete interpreter with decision precedure
%    \begin{tikzpicture}
%    \end{tikzpicture}
%    \end{minipage}
%    \hfill
%    \begin{minipage}[t]{0.45\textwidth}
%        fully instrumented abstraction with decision procedure + concrete interpreter
%    \begin{tikzpicture}
%    \end{tikzpicture}
%    \end{minipage}

\centering
\resizebox{\textwidth}{!}{
\begin{tikzpicture}[node distance=1.2em]
    \node [] (program) {\textsc{program}};
    \node [component, minimum width = 20em, inner sep = 3pt, below = of program] (p1) {concrete data};
    \node [component, minimum width = 20em, inner sep = 3pt, below = 2em of p1.west, anchor = west] (p2) {concrete + abstract data};
    \node [component, minimum width = 12em, inner sep = 3pt, below = 2em of p2.west, anchor = west] (p3) {concrete + abstract data};
    \node [component, minimum width = 8em, inner sep = 3pt, right = 0em of p3] (p3meta) {meta};

    \node [component, minimum width = 12em, inner sep = 3pt, below = 2em of p3.west, anchor = west] (p4) {concrete + abstract data};
    \node [component, minimum width = 4em, inner sep = 3pt, right = 0em of p4] (p4meta) {meta};
    \node [component, minimum width = 4em, inner sep = 3pt, right = 0em of p4meta] (p4dp) {\textsc{DP}};

    %\node [right = 15em of program] (vm) {\textsc{interpreter}};
    \node [component, minimum width = 15em, inner sep = 3pt, right = of p4dp] (ai4) {explicit data};
    \node [component, minimum width = 11em, inner sep = 3pt, above = 2em of ai4.west, anchor = west] (ai3) {explicit data};
    \node [right = 0.5em of ai3] (ai3dpp) {+};
    \node [right = 0.25em of ai3dpp] (ai3dp) {\textsc{dp}};

    \node [component, minimum width = 7em, inner sep = 3pt, above = 2em of ai3.west, anchor = west] (ai2) {explicit data};
    \node [component, minimum width = 4em, inner sep = 3pt, right = 0em of ai2] (ai2meta) {meta};
    \node [right = 0.5em of ai2meta] (ai2dpp) {+};
    \node [right = 0.25em of ai2dpp] (ai2dp) {\textsc{dp}};

    \node [component, minimum width = 7em, inner sep = 3pt, above = 2em of ai2.west, anchor = west] (ai1) {abstract data};
    \node [component, minimum width = 4em, inner sep = 3pt, right = 0em of ai1] (ai1meta) {meta};
    \node [right = 0.5em of ai1meta] (ai1dpp) {+};
    \node [right = 0.25em of ai1dpp] (ai1dp) {\textsc{dp}};

    \node (interpreter) at (program -| ai4.north) {\textsc{interpreter}};

    \node (top) at ($(program.north)!0.57!(interpreter.north)$) {};
    \node (bot) at (top |- ai4.south) {};

    \node [left = of p1] (l1) {1.};
    \node [left = of p2] (l2) {2.};
    \node [left = of p3] (l3) {3.};
    \node [left = of p4] (l4) {4.};

    \draw [dashed] (top.north) -- (bot.south);
\end{tikzpicture}
}

\bigskip
\prule

\begin{enumerate}
    \item The first boundary is a common approach to abstract
        interpretation where, the interpreter takes carer of whole abstraction
        (maintaining abstract data, additional metadata and optionally uses
        decision procedure \textsc{dp}).
    \item In the second approach, we let the program to take care of abstract
        data (this can be achieved by instrumentation as described
        in~\autoref{sec:symbolic}).  However, interpreter still keeps metadata
        that keeps track for each value, whether it is abstract or concrete.
        This information is used when interpreter needs to decide how to
        interpret program memory -- whether to perform an explicit or abstract
        comparison of states.
    \item The third approach shifts responsibility about metadata to
        the program (they can be kept as shadow memory of the program -- a
        similar approach is used by sanitizers~\cite{Stepanov2015}), consequently the
        interpreter needs to extract metadata from the program.
    \item The latter approach let full responsibility about abstraction to the
        program, and the interpreter executes program explicitly. The decision
        procedure needs to take care of non-deterministic execution and
        determine what path to take when a non-deterministic branch occurs. Or
        the responsibility of the non-determinism can be left to the
        interpreter. Alternatively, one can encode the vector of decisions to
        the program and create an executable abstract program.
\end{enumerate}

\caption{Possible division of abstraction responsibilities between program and interpreter.}
\label{fig:bounds}

\end{figure}

% TODO nondeterministic control flow

% describe boundaries between program and execution engine
% 1. pure program + abstract engine
% 2. abstract program + engine with metadata
% 3. abstracted program with metadata  +  concrete engine
% 4. abstracted program with decision procedure + concrete execution

\section{Objectives and Expected Results}
\label{sec:objectives}

Similarly, as many successful state-of-the-arts tools do, we will devise our
techniques on top of \llvm intermediate representation. The \llvm framework
provides an easily instrumantable input language but also enables many other
tools to use our analysis further, what is our primary goal.

\subsection{Data flow analysis}

To be able to instrument abstraction into the program, first of all, we need to
perform a data flow analysis to detect wherever abstract values might appear.
Such analysis needs to be efficient and fast, and it needs to handle data flow
through program memory, indirect calls as well as perform pointer analyses. Even though we can
overapproximate its result, we want to minimize the amount of instrumented
abstraction to retain precision of further analysis.

The contemporary techniques are usually imprecise or they handle only a subset of use
cases of real progras. Hence the first goal of successful abstraction is a
\emph{memory aware data flow analysis}. To achieve better results, I want to
investigate a different approach of approximated data flow analysis, which will
combine refinement and program transformation.  We propose to use refinement
and transformation to ease the analysis of imprecise (hard to analyze) points
in the program, e.g., indirect calls and memory manipulations.

\subsection{Trivially constrainable domains}

The next goal to reusable abstraction is to implement a trivially constrainable
abstraction. It is an abstraction which does not require any refinement for its
use. One such abstraction is a symbolic abstraction -- in the symbolic
abstraction all data are represented by formulas and constraints are maintained
in a path condition. I have already implemented a symbolic abstraction as
program transformation, and it is published in~\cite{Lauko2018SymComp}.
It is further summarized in my achieved results -- \autoref{ch:results}.

\subsection{Non-relational abstract domains}

In comparison to an abstract interpreter, a program, that executes abstract
computation by itself, cannot perform interpretation to some fixpoint. Hence,
to achieve an extended precision, we need to instrument some precision
mechanism into the program. In the transformed program, abstract data flows
forward as if an interpreter propagated them. However, an imprecision arises on
the conditional branching that depends on an abstract value. When such a branch
is executed, both outcomes might be admissible, in that case, we need to
examine both possibilities. \add{ nondeterministic choice TODO note }
Furthermore, continuing one way does not ensure that values were constrained
according to the branch condition. Accordingly, we need to instrument an assume
operation that will recompute a constrained value. Moreover, other values might
be relationally dependent on the constrained values -- therefore we need to
propagate constraints to some extent of precision backward. Eventually, we
might use some global relational structure as is used in symbolic execution --
path condition.

In my work, I want to investigate \emph{backward constraints propagation} and
its adaptation to \cegar-based techniques with the application of predicate
abstraction. For this use case, I would like to repurpose the bucketing/state
partitioning techniques from abstract interpretation to simplify sets of
possibly related variables.

\add{ incorporate widening/narrowing into the refinement }

\add{ example }

\subsection{Abstraction refinement}


A final challenge of my research would be to define a general \cegar loop in the
means of transformation based abstraction. The main challenge here is how to
remap counterexample back to instrumentation.

Hand-in-hand with \cegar comes multiple possible refinement techniques inspired
by the \smt community: program variables bitwidth abstraction, theory refinement
or lazy abstraction approaches. The final symbolic approach might be extended
to function summarization and bottom-up program verification.

% \add{ refinement steps }
% \add{ counterexample encoding }
% refinement techniques from chapter 2
% variables packing
% abstraction encoding

% \subsubsection{SMT inspired refinement techniques}
%\add{ bitwidth abstraction }
%\add{ theory refinement}
%\add{ function summarization }

\subsection{ Domain categories }

In addition to numeric abstract domains we want to cover other techniques like
shape analysis and heap abstractions -- here I want to focus on how to
generalize these abstractions. In our transformation framework, we distinguish
three categories of abstract domains:

\begin{itemize}
    \item \emph{scalar domains} that abstract program integers and floating-point values (correspond to numeric abstract domains),
    \item \emph{aggregate domains} that abstract a program objects and memory content like arrays and strings,

    \item \emph{pointer domains} that enable to abstract program pointers.
\end{itemize}

In the next chapter I present my achieved results in the instrumentation of scalar and aggregate domains.

\add{ automatic testing of abstract domains \cite{Bugariu2018} }

% aggregate domains (abstract only offset)
% \add{ pointer domains }
% pointer domains (abstract address/offset)

\subsection{ Executable abstraction }

The hitherto presented abstraction relied on the underlying execution engine,
which maintained abstraction metadata and enabled non-deterministic program
branching. However, for the future, I plan to investigate a possibility of a
runnable abstraction for a particular run of non-deterministic choices with the
use of data flow sanitizer [TODO] (see fourth option of \autoref{fig:bounds})
-- such program provides an option of executable counterexample to be analyzed
by general-purpose analysis of \llvm programs (e.g., debuggers).  The data flow
sanitizer enables program to keep track of metadata and propagates them during
execution -- allows to perform a taint analysis, where taints identify abstract
values in the program.

\add{ \cite{Gennari2018} }

\add{ seahorn - bing seahorn capabilities to other tools }

\section{Progression Schedule}

\add{ TODO }

% DFA

% Cegar

% SMT based refinements

% Domain tutorial + testing

% Executable domain

% Thesis
