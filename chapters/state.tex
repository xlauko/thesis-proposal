\chapter{State of the art}
\label{ch:state}

% Současný stav řešené problematiky, přehled klasických i aktuálních výsledků a jejich porovnání, analýza problematiky vedoucí k vymezení oblasti zájmu budoucí disertační práce, 8 - 12 stran.


% Handbook of mode checking
%   - 3.2.1.4 Level of Abstraction
%   - 3.4.1.4 Data Type Abstraction:
% The choice of how to model the data type of the flit can have a big impact on the
% scalability of verification.
%
% Chapter 13:
% Abstraction tackles this challenge based on the assumption that a reduction of
% the information content results in a reduction of the size of the representation of
% a Kripke structure.
%
% Clanky:
% The topic of constructing abstractions is
% also one of the focuses of the theory of Abstract Interpretation [8, 37–40, 76], which
% is not treated in this chapter.

% TODO prerequisites

\section{Preliminaries}

This section introduces the notation used in the rest of the thesis proposal.
The presented notation is mainly based on the configurable software
verification technique \cite{Beyer2007, Beyer2018, Beyer2018b} and Cousot's
notation used to describe abstract interpretation \cite{Cousot2012}.

\subsection{Programs, Control-Flow Graph, States}

We restrict the presentation to a simplified version of \llvm programs
\cite{Lattner04}. An elementary unit of \llvm program is an instruction. We
distinguish binary instructions (arithmetic operations, relational operations),
memory access operations, data flow operations (branching instructions, calls,
return instructions). Because \llvmir is a typed language, it provides also
casting instructions. We admit scalar types (floats, integers), pointer types,
and aggregate types (arrays, structures).\sidenote{For detailed syntax and
semantics description see \autoref{ch:llvm}.}

The entire program in \llvm consists of global variables and functions.  A
function is a directed graph of basic blocks. A basic block is a sequence of
non-terminal instructions terminated by a terminal instruction.\sidenote{A
terminal instruction is either branching or return instruction.}

For a more accessible representation of an \llvm program, we will use a
\emph{control flow automaton} (CFA), which is a directed graph with \llvm
instructions attached to its edges (see \autoref{fig:cfa}).

\begin{definition}
    Given a set of instructions $\mathcal{I}$, a control flow automaton
    $\mathcal{A}$ is a tuple $(\mathcal{L}, l_{\textit{init}}, \mathcal{G})$,
    where $\mathcal{L}$ is a set of program locations, $l_{\textit{init}} \in
    \mathcal{L}$ is an initial location that represents a program entry point
    and $\mathcal{G} \subseteq (\mathcal{L} \times \mathcal{I} \times
    \mathcal{L})$ is set of edges between program locations, each labeled with
    an instruction that is executed when the control flows along the edge.
\end{definition}

The set of all variables that occur in the \llvm program is denoted by
$\mathcal{V}$.\sidenote{In addition to program variables, we will also consider
\llvm registers as variables. Even though \llvm registers are only assigned
ones in the \ssa.} A \emph{concrete state} $\sigma : \mathcal{V} \rightarrow
\mathsf{C}$ is a mapping from program variables to concrete values. We denote
the set of all concrete states as $\Sigma$. Thus, the concrete state can be
viewed as a state of program's memory that holds the value for each program
variable. A~set of admissible states at some location $l \in \mathcal{L}$ is
called a \emph{context} $\mathcal{C}_l \subseteq \mathcal{P}(\Sigma)$.

The semantics of instruction $i \in \mathcal{I}$ is defined by \emph{strongest
post condition} $SP_{i}(\cdot)$, i.e. it is executed on a particular program
state a accordingly updates values of program variables -- for further details
see \autoref{ch:llvm}.

A set of all edges $\mathcal{G}$ induces a transition relation $\rightarrow$ on
the set of states $\Sigma$, such that for each $g \in \mathcal{G}$ there is
$\xrightarrow{g} \: \subseteq \Sigma \times \{g\} \times \Sigma$. The
transition relation is a union over all edges $\rightarrow \bigcup_{g
\in\mathcal{G}} \xrightarrow{g}$.

A \emph{program path} $\pi$ TODO
%is a sequence of concrete states $\langle c_0, c_1,
%\dots, c_n \rangle$ such that for all $1 \leq i \leq n$ there is a edge
%$c_{i-1} \rightarrow c_i$. The semantics of path $\pi$ is defined by iterative
%application of $SP_{i}( \cdot )$ for each instruction in path $\pi$. Given
%initial constraints on variables, the path  Given initial constraints on
%variables $\phi$, the strongest postcondition of path $\pi$ is
%$\textsf{SP}_{\pi} = \textsf{SP}_{i_n}(\dots,$. A path $\pi$ is called
%\emph{feasible} if $SP_{\pi}(\textit{true})$ is satisfiable and
%\emph{infeasible} otherwise. A concrete state $\sigma \in \Sigma$ is
%\emph{reachable} from \emph{region} $r$ if there exists a feasible path $\pi$
%starting from state $c_0 \in r$.

A \emph{verification task} for  CFA $\mathcal{A} = (\mathcal{L},
l_{\textit{init}}, \mathcal{G})$ is to show that error location
$l_{\textit{err}} \in \mathcal{L}$ is unreachable in $\mathcal{A}$, or to find
feasible error path.

\begin{figure}

\begin{minipage}[t]{0.5\textwidth}
\begin{minted}[linenos]{llvm}
define i32 @main() {
entry:
  %x = alloca i32
  store i32 0 to i32* %x
  br label %loop
loop:
  %v = load i32* %x
  %a = add i32 %v, 1
  store i32 %a to i32* %x
  %b = icmp ult i32 %a, 5
  br %b, label %loop, label %end
end:
  ret i32 0
}
\end{minted}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
\strut\vspace*{-\baselineskip}\newline\centering
\begin{tikzpicture}[node distance=1.1em]
    \node [loc] (l1) {$l_1$};
    \node [lab, left = 0cm of l1] (entry) {\llvmint{entry:}};

    \node [loc, below = of l1] (l2) {$l_2$};
    \node [loc, below = of l2] (l3) {$l_3$};
    \node [lab, left = 0cm of l3] (loop) {\llvmint{loop:}};

    %\node[fit=(l1) (l2), draw, dashed] (ebb) {};

    \node [loc, below = of l3] (l4) {$l_4$};
    \node [loc, below = of l4] (l5) {$l_5$};
    \node [loc, below = of l5] (l6) {$l_6$};
    \node [loc, below = of l6] (l7) {$l_7$};

    %\node[fit=(l3) (l4) (l5) (l6) (l7), draw, dashed] (lbb) {};

    \node [loc, below = of l7] (l8) {$l_8$};
    \node [lab, left = 0cm of l8] (loop) {\llvmint{end:}};

    \node [loc, below = of l8] (l9) {$l_9$};

    %\node[fit=(l8) (l9), draw, dashed] (lbb) {};

    \draw [->, >=stealth] (l1) -- node[midway, right] {\llvmint{|\var{\%x}| = alloca i32}} (l2);
    \draw [->, >=stealth] (l2) -- node[midway, right] {\llvmint{store 0 to |\var{\%x}|}} (l3);
    \draw [->, >=stealth] (l3) -- node[midway, right] {\llvmint{|\var{\%v}| = load |\var{\%x}|}} (l4);
    \draw [->, >=stealth] (l4) -- node[midway, right] {\llvmint{|\var{\%a}| = add |\var{\%v}| 1}} (l5);
    \draw [->, >=stealth] (l5) -- node[midway, right] {\llvmint{store |\var{\%a}| to |\var{\%x}|}} (l6);
    \draw [->, >=stealth] (l6) -- node[midway, right] {\llvmint{|\var{\%b}| = ult |\var{\%a}| 5}} (l7);
    \draw [->, >=stealth] (l7) -- node[midway, right] {\llvmint{[|\var{\%b}| = false]}} (l8);
    \draw [->, >=stealth] (l7) to [bend left=40] node[above, rotate = 90] {\llvmint{[|\var{\%b}|= true]}} (l3);
    \draw [->, >=stealth] (l8) -- node[midway, right] {\llvmint{ret 0}} (l9);

\end{tikzpicture}
\end{minipage}

\caption{An example of \llvm program (left) and its CFA (right).}
\label{fig:cfa}
\end{figure}

\section{Abstract Interpretation}

The original idea of abstract interpretation dates back to the late 70s, first
summarized by Patrick and Radhia Cousot \cite{Cousot1977}.
Cousot describes \emph{abstract interpretation} as a theory of abstraction and
constructive approximation of the mathematical structures used in the formal
description of programming languages and the inference or verification of
undecidable program properties~\cite{Cousot2012}.


% TODO incorporate https://link.springer.com/content/pdf/10.1007%2F978-3-540-39910-0_11.pdf
For our course, the goal of abstract interpretation is to assign each program
location a context in a given domain. Program contexts are computed by solving
a system of fixpoint equations generated from a transition function
$\textsf{SP}$ \cite{Cousot1977}. Such computation simulates the execution of a
program in a given domain. As a result, each context contains all values that
might all variables obtain after the execution of the program with arbitrary
input. The states\sidenote{State of computation comprise of all intermediate
contexts assigned to program locations.} of the computation forms a complete
lattice: $(S, \sqcap, \sqcup, \sqsubseteq, \top, \bot)$, where $S$ is a set of
states, $\sqcup$, $\sqcap$ are meet and join operators, $\sqsubseteq$ ordering
of a lattice, $\top$ is the greatest element and $\bot$ it the least element of
the lattice. Throughout the rest of the thesis proposal we will assume
familiarity with the basic notions of lattice theory \cite{Birkhoff1940}.

Given the concrete contexts from previous definitions, the \emph{concretp
semantic domain} is a complete lattice $(\mathcal{P}(\Sigma), \cap, \cup,
\subseteq, \Sigma, \emptyset)$. Even though this technique gives us a tool to
compute all possible states that a program might reach, it is, unfortunately,
uncomputable (it can be easily shown by reduction to halting problem). To
mitigate the problem of computability, we employ an abstract domain instead of
a concrete one. In the following sections, we will investigate various types of
abstract domains with their advantages and disadvantages.

\section{Abstract Domains}


To obtain a computable model, we need to drop some information about program
variables. For instance, to drop all the information about each program
variable except whether it is positive negative or zero. This can be achieved
by replacement of values domain we are computing on $\mathsf{C}$ by an abstract
domain $\domainm{sign} = \{ \bot, -, 0, +, \top)$ =, where $\bot$ represents an
undefined value (variable without assigned value), $+$,$-$ and $0$ denote a
\begin{marginfigure}%
    \centering
    \begin{tikzpicture}[node distance=1em]
    \node [] (t) {$\top$};
    \node [below = of t] (0) {$0$};
    \node [left = of 0] (m) {$-$};
    \node [right = of 0] (p) {$+$};
    \node [below = of 0] (b) {$\bot$};
    \draw [thin] (t) -- (m) -- (b);
    \draw [thin] (t) -- (0) -- (b);
    \draw [thin] (t) -- (p) -- (b);
    \end{tikzpicture}
    \caption{$\mathsf{A}_{\textit{sign}}$ domain lattice.}
    \label{fig:signd}%
\end{marginfigure}%
sign of variable and $\top$ is for an arbitrary value (i.e., variable can be
either negative, positive or zero).

\begin{figure}%
\begin{minipage}[t]{0.3\textwidth}
\strut\vspace*{-\baselineskip}\newline\centering
\resizebox{\textwidth}{!}{
\begin{tikzpicture}[node distance=1.1em]
    \node [loc] (l1) {$l_1$};
    \node [lab, left = 0cm of l1] (entry) {\llvmint{entry:}};
    \node [lab, right = 0cm of l1] (e1) {$(\bot, \bot, \bot, \bot)$};

    \node [loc, below = of l1] (l2) {$l_2$};
    \node [lab, right = 0cm of l2] (e2) {$(\bot, \bot, \bot, \bot)$};
    \node [loc, below = of l2] (l3) {$l_3$};
    \node [lab, left = 0cm of l3] (loop) {\llvmint{loop:}};
    \node [lab, right = 0cm of l3] (e3) {$(0, \bot, \bot, \bot)$};

    %\node[fit=(l1) (l2), draw, dashed] (ebb) {};

    \node [loc, below = of l3] (l4) {$l_4$};
    \node [lab, right = 0cm of l4] (e4) {$(\bot, \bot, \bot, \bot)$};
    \node [loc, below = of l4] (l5) {$l_5$};
    \node [lab, right = 0cm of l5] (e5) {$(\bot, \bot, \bot, \bot)$};
    \node [loc, below = of l5] (l6) {$l_6$};
    \node [lab, right = 0cm of l6] (e6) {$(\bot, \bot, \bot, \bot)$};
    \node [loc, below = of l6] (l7) {$l_7$};
    \node [lab, right = 0cm of l7] (e7) {$(\bot, \bot, \bot, \bot)$};

    %\node[fit=(l3) (l4) (l5) (l6) (l7), draw, dashed] (lbb) {};

    \node [loc, below = of l7] (l8) {$l_8$};
    \node [lab, left = 0cm of l8] (loop) {\llvmint{end:}};
    \node [lab, right = 0cm of l8] (e8) {$(\bot, \bot, \bot, \bot)$};

    \node [loc, below = of l8] (l9) {$l_9$};
    \node [lab, right = 0cm of l9] (e9) {$(\bot, \bot, \bot, \bot)$};

    %\node[fit=(l8) (l9), draw, dashed] (lbb) {};

    \draw [->, >=stealth] (l1) -- node[midway, right] {\llvmint{|\var{\%x}| = alloca i32}} (l2);
    \draw [->, >=stealth] (l2) -- node[midway, right] {\llvmint{store 0 to |\var{\%x}|}} (l3);
    \draw [->, >=stealth] (l3) -- node[midway, right] {\llvmint{|\var{\%v}| = load |\var{\%x}|}} (l4);
    \draw [->, >=stealth] (l4) -- node[midway, right] {\llvmint{|\var{\%a}| = add |\var{\%v}| 1}} (l5);
    \draw [->, >=stealth] (l5) -- node[midway, right] {\llvmint{store |\var{\%a}| to |\var{\%x}|}} (l6);
    \draw [->, >=stealth] (l6) -- node[midway, right] {\llvmint{|\var{\%b}| = ult |\var{\%a}| 5}} (l7);
    \draw [->, >=stealth] (l7) -- node[midway, right] {\llvmint{[|\var{\%b}| = false]}} (l8);
    \draw [->, >=stealth] (l7) to [bend left=40] node[above, rotate = 90] {\llvmint{[|\var{\%b}|= true]}} (l3);
    \draw [->, >=stealth] (l8) -- node[midway, right] {\llvmint{ret 0}} (l9);
\end{tikzpicture}
}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\textwidth}
\strut\vspace*{-\baselineskip}\newline\centering
\resizebox{\textwidth}{!}{
\begin{tikzpicture}[node distance=1.1em]
    \node [loc] (l1) {$l_1$};
    \node [lab, left = 0cm of l1] (entry) {\llvmint{entry:}};
    \node [lab, right = 0cm of l1] (e1) {$(\bot, \bot, \bot, \bot)$};

    \node [loc, below = of l1] (l2) {$l_2$};
    \node [lab, right = 0cm of l2] (e2) {$(\bot, \bot, \bot, \bot)$};
    \node [loc, below = of l2] (l3) {$l_3$};
    \node [lab, left = 0cm of l3] (loop) {\llvmint{loop:}};
    \node [lab, right = 0cm of l3] (e3) {$(0, \bot, \bot, \bot)$};

    %\node[fit=(l1) (l2), draw, dashed] (ebb) {};

    \node [loc, below = of l3] (l4) {$l_4$};
    \node [lab, right = 0cm of l4] (e4) {$(0, 0, \bot, \bot)$};
    \node [loc, below = of l4] (l5) {$l_5$};
    \node [lab, right = 0cm of l5] (e5) {$(0, 0, +, \bot)$};
    \node [loc, below = of l5] (l6) {$l_6$};
    \node [lab, right = 0cm of l6] (e6) {$(+, 0, +, \bot)$};
    \node [loc, below = of l6] (l7) {$l_7$};
    \node [lab, right = 0cm of l7] (e7) {$(+, 0, +, \top)$};

    %\node[fit=(l3) (l4) (l5) (l6) (l7), draw, dashed] (lbb) {};

    \node [loc, below = of l7] (l8) {$l_8$};
    \node [lab, left = 0cm of l8] (loop) {\llvmint{end:}};
    \node [lab, right = 0cm of l8] (e8) {$(\bot, \bot, \bot, \bot)$};

    \node [loc, below = of l8] (l9) {$l_9$};
    \node [lab, right = 0cm of l9] (e9) {$(\bot, \bot, \bot, \bot)$};

    %\node[fit=(l8) (l9), draw, dashed] (lbb) {};

    \draw [->, >=stealth] (l1) -- node[midway, right] {\llvmint{|\var{\%x}| = alloca i32}} (l2);
    \draw [->, >=stealth] (l2) -- node[midway, right] {\llvmint{store 0 to |\var{\%x}|}} (l3);
    \draw [->, >=stealth] (l3) -- node[midway, right] {\llvmint{|\var{\%v}| = load |\var{\%x}|}} (l4);
    \draw [->, >=stealth] (l4) -- node[midway, right] {\llvmint{|\var{\%a}| = add |\var{\%v}| 1}} (l5);
    \draw [->, >=stealth] (l5) -- node[midway, right] {\llvmint{store |\var{\%a}| to |\var{\%x}|}} (l6);
    \draw [->, >=stealth] (l6) -- node[midway, right] {\llvmint{|\var{\%b}| = ult |\var{\%a}| 5}} (l7);
    \draw [->, >=stealth] (l7) -- node[midway, right] {\llvmint{[|\var{\%b}| = false]}} (l8);
    \draw [->, >=stealth] (l7) to [bend left=40] node[above, rotate = 90] {\llvmint{[|\var{\%b}|= true]}} (l3);
    \draw [->, >=stealth] (l8) -- node[midway, right] {\llvmint{ret 0}} (l9);
\end{tikzpicture}
}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\textwidth}
\strut\vspace*{-\baselineskip}\newline\centering
\resizebox{\textwidth}{!}{
\begin{tikzpicture}[node distance=1.1em]
    \node [loc] (l1) {$l_1$};
    \node [lab, left = 0cm of l1] (entry) {\llvmint{entry:}};
    \node [lab, right = 0cm of l1] (e1) {$(\bot, \bot, \bot, \bot)$};

    \node [loc, below = of l1] (l2) {$l_2$};
    \node [lab, right = 0cm of l2] (e2) {$(\bot, \bot, \bot, \bot)$};
    \node [loc, below = of l2] (l3) {$l_3$};
    \node [lab, left = 0cm of l3] (loop) {\llvmint{loop:}};
    \node [lab, right = 0cm of l3] (e3) {$(\top, \top, \top, \top)$};

    %\node[fit=(l1) (l2), draw, dashed] (ebb) {};

    \node [loc, below = of l3] (l4) {$l_4$};
    \node [lab, right = 0cm of l4] (e4) {$(\top, \top, \top, \top)$};
    \node [loc, below = of l4] (l5) {$l_5$};
    \node [lab, right = 0cm of l5] (e5) {$(\top, \top, \top, \top)$};
    \node [loc, below = of l5] (l6) {$l_6$};
    \node [lab, right = 0cm of l6] (e6) {$(\top, \top, \top, \top)$};
    \node [loc, below = of l6] (l7) {$l_7$};
    \node [lab, right = 0cm of l7] (e7) {$(\top, \top, \top, \top)$};

    %\node[fit=(l3) (l4) (l5) (l6) (l7), draw, dashed] (lbb) {};

    \node [loc, below = of l7] (l8) {$l_8$};
    \node [lab, left = 0cm of l8] (loop) {\llvmint{end:}};
    \node [lab, right = 0cm of l8] (e8) {$(\top, \top, \top, \top)$};

    \node [loc, below = of l8] (l9) {$l_9$};
    \node [lab, right = 0cm of l9] (e9) {$(\top, \top, \top, \top)$};

    %\node[fit=(l8) (l9), draw, dashed] (lbb) {};

    \draw [->, >=stealth] (l1) -- node[midway, right] {\llvmint{|\var{\%x}| = alloca i32}} (l2);
    \draw [->, >=stealth] (l2) -- node[midway, right] {\llvmint{store 0 to |\var{\%x}|}} (l3);
    \draw [->, >=stealth] (l3) -- node[midway, right] {\llvmint{|\var{\%v}| = load |\var{\%x}|}} (l4);
    \draw [->, >=stealth] (l4) -- node[midway, right] {\llvmint{|\var{\%a}| = add |\var{\%v}| 1}} (l5);
    \draw [->, >=stealth] (l5) -- node[midway, right] {\llvmint{store |\var{\%a}| to |\var{\%x}|}} (l6);
    \draw [->, >=stealth] (l6) -- node[midway, right] {\llvmint{|\var{\%b}| = ult |\var{\%a}| 5}} (l7);
    \draw [->, >=stealth] (l7) -- node[midway, right] {\llvmint{[|\var{\%b}| = false]}} (l8);
    \draw [->, >=stealth] (l7) to [bend left=40] node[above, rotate = 90] {\llvmint{[|\var{\%b}|= true]}} (l3);
    \draw [->, >=stealth] (l8) -- node[midway, right] {\llvmint{ret 0}} (l9);
\end{tikzpicture}
}
\end{minipage}
    \caption{\domain{sign} fixpoint iteration for variables
    (\llvmint{|\var{\%x}, \var{\%v}, \var{\%a}, \var{\%b}|}). A~tuple at each
    location represents an abstract evaluation of the variables in this order.
    The presented states of iteration are after first iteration
    (\textbf{left}), after 5 iterations (\textbf{middle}), reached fixpoint
    (\textbf{right}).}
    \label{fig:signcomp}%
    \add{todo page width}
\end{figure}%

We say that $\mathsf{A}$ is an abstraction of $\mathsf{C}$ because it carries
less information about program variables. One requirement on $\mathsf{A}$ is
that its values form a complete lattice (see \autoref{fig:signd}). Moreover, a
well-defined domain is required to have an image for each concrete value and
that $\mathcal{A}$ is over approximating abstraction. Such properties of
domains are described by Galois connection:
%For concrete lattice $(C, \subseteq)$ and abstract lattice $(A, \sqsubseteq)$:
%\textbf{1. Abstraction over-approximates:}
%\textbf{2. Abstraction after concretisation yields no imprecision:}
\begin{definition}
    If $(C, \subseteq)$ and $(A, \sqsubseteq)$ are posets and $\alpha : C
    \rightarrow A$, $\gamma : A \rightarrow C$ are monotonic functions such
    that:
    \[
        \forall c \in C.\: c \subseteq \gamma( \alpha( c ) )
         \quad \text{and} \quad
        \forall a \in A.\: \alpha( \gamma( a ) ) \sqsubseteq a
    \]
    we call $(\alpha, \gamma)$ a \textbf{Galois connection} for posets $C$ and
    $A$.
\end{definition}

\noindent
In abstract interpretation $C$ and $A$ are called \emph{concrete} respectivelly
\emph{abstract} domain and they are assumed to be complete lattices. We call
$\alpha$ the \emph{abstraction} map and $\gamma$ the \emph{concretization} map.
\add{galois connection image}

Given an abstract domain and abstract operations\sidenote{In our case a
definition how \llvm instructions transform abstract values.} we can perform a
fixpoint iteration\sidenote{For detailed algorithm see \cite{Cousot1977}} a
by Knaster-Tarski theorem \cite{Tarski1955} we are guaranteed to obtain a
solution, see \autoref{fig:signcomp}.

\add{ induced operation by abstraction}

\begin{marginfigure}%
    \centering
\resizebox{\textwidth}{!}{
    \begin{tikzpicture}[node distance=1em]
    \node [] (t) {$\top$};
    \node [below = 3em of t] (0) {$0$};
    \node [left = of 0] (m1) {$-1$};
    \node [left = of m1] (m2) {$-2$};
    \node [left = of m2] (m) {$\dots$};
    \node [right = of 0] (p1) {$1$};
    \node [right = of p1] (p2) {$2$};
    \node [right = of p2] (p) {$\dots$};
    \node [below = 3em of 0] (b) {$\bot$};
    \draw [thin] (t) -- (m) -- (b);
    \draw [thin] (t) -- (m2) -- (b);
    \draw [thin] (t) -- (m1) -- (b);
    \draw [thin] (t) -- (0) -- (b);
    \draw [thin] (t) -- (p1) -- (b);
    \draw [thin] (t) -- (p2) -- (b);
    \draw [thin] (t) -- (p) -- (b);
    \end{tikzpicture}
}
    \caption{\domain{cp} domain lattice.}
    \label{fig:cp}%
\end{marginfigure}%
Even though our example program in \autoref{fig:signcomp} is quite trivial, the
sign domain \domain{sign} was not able to preserve any interesting properties,
and all resulting contexts are either $\top$ or $\bot$.  Sign domain belongs to
the class of simple domains that track only single property about variables --
also known as \emph{property domains}. Another famous example of a property
domain is a \textbf{\emph{parity domain}}, which tracks only whether the
variable is odd or even. The parity domain is just a special case of a
\textbf{\emph{congruence domain}} \cite{Granger1989, Granger1991}.
%In congruence domain, a set of values is abstracted to the least common set where each variable has the form $a\mathbb{Z} + b$ .

A~\textbf{\emph{constant propagation domain}} \domain{cp} (see
\autoref{fig:cp}) has used another example of property domain (i.e., variable
can gain only single value) used in optimization techniques \cite{Kildall1973}.
Property domains can be combined to track multiple properties either by
tracking each property separately or by joining lattice of multiple
abstractions (see \autoref{fig:cpsign}).
\add{find citation for decomposition of abstract domains}
\begin{marginfigure}%
    \centering
\resizebox{\textwidth}{!}{
    \begin{tikzpicture}[node distance=1em]
    \node [] (t) {$\top$};
    \node [below = 6em of t] (0) {$0$};
    \node [left = of 0] (m1) {$-1$};
    \node [left = of m1] (m2) {$-2$};
    \node [above = 3em of m2] (mm) {$-$};
    \node [left = of m2] (m) {$\dots$};
    \node [right = of 0] (p1) {$1$};
    \node [right = of p1] (p2) {$2$};
    \node [right = of p2] (p) {$\dots$};
    \node [above = 3em of p2] (pp) {$+$};
    \node [below = 3em of 0] (b) {$\bot$};
        \draw [thin] (t) -- (mm) -- (m)  -- (b);
        \draw [thin] (t) -- (mm) -- (m2) -- (b);
        \draw [thin] (t) -- (mm) -- (m1) -- (b);
    \draw [thin] (t) -- (0) -- (b);
        \draw [thin] (t) -- (pp)-- (p1) -- (b);
        \draw [thin] (t) -- (pp)-- (p2) -- (b);
        \draw [thin] (t) -- (pp) -- (p) -- (b);
    \end{tikzpicture}
}
    \caption{\domain{cs} is a joint sign (\domain{sign}) and constant propagation (\domain{cp}) domain.}
    \label{fig:cpsign}%
\end{marginfigure}%

Probably the simplest of domains is a definedness domain \domain{D}, which only
tracks a definedness of values (see \autoref{fig:unitd}). Despite its
simplicity, it can be useful to detect reachability of program locations. Even
simpler domain is a single value domain \domain{U}. The single value domain is
usefull if we want to omit a variable from the model of the program.

\begin{marginfigure}%
    \centering
    \begin{tikzpicture}[node distance=1em]
    \node [] (t) {$\top$};
    \node [below = of t] (b) {$\bot$};
    \draw [thin] (t) -- (b);
    \end{tikzpicture}
    \caption{\domain{U} tracks only definedness of variables.}
    \label{fig:unitd}%
\end{marginfigure}%

Since the precision of an abstract domain highly depends on the program
structure, many abstract domains were designed to track various program
properties. Let us take it chronologically. The first domain presented in
Cousot's paper \cite{Cousot1977} to achieve more precise results was an
\textbf{\emph{interval domain}} \domain{I}. In the interval abstraction a set of values
is represented by its minimal and maximal value. Since in some cases, it is not
possible to determine the boundary values, the interval domain utilizes
infinities to denote arbitrary bound -- we represent arbitrary value
$\top_{\textit{I}}$ by $[-\infty, \infty]$ and undetermined value $\bot_{\textit{I}}$
by empty interval $\emptyset$.

\add{ lattice of abstract domains}

Unfortunately, with the infinite lattice of the interval
domain,\sidenote{The interval domain does not meet ascending chain condition.} the
abstract interpretation obtained a possible infinite or impractically long
executions (e.g., when the interpretation can not determine the bound of a loop
it can increment the boundary of an interval indefinitely never reaching the
fixpoint). For this reason, abstract interpreters employ widening and
narrowing techniques to accelerate convergence \cite{Cousot1992a, Cortesi2011}.
The idea of widening is to overshoot the least fixpoint after few
unsuccessful iterations of the interpretation and subsequently by narrowing to
refine the over-approximated solution.
\begin{definition}
    \textbf{Widening operator} $\nabla$ for domain $(\mathcal{A},
    \sqsubseteq)$ fulfills:
    \begin{enumerate}
        \item $\forall v_1, v_2 \in \mathcal{A} : v_1 \sqcup v_2 \sqsubseteq v_1 \nabla v_2$,
        \item for each sequence $(v_k)_{k \in \mathbb{N}}$, the sequence $(v^{\nabla}_k)_{k \in \mathbb{N}}$ defined as $v^{\nabla}_0 = v_0$ and $v^{\nabla}_k = v^{\nabla}_{k-1} \nabla v_k$ reaches a fixpoint after finitely many steps.
    \end{enumerate}
\end{definition}
\begin{definition}
    \textbf{Narrowing operator} $\Delta$ for domain $(\mathcal{A},
    \sqsubseteq)$ fulfills:
    \begin{enumerate}
        \item $\forall v_1, v_2 \in \mathcal{A} : v_1 \sqsupseteq v_2 \implies v_1 \Delta v_2 \sqsubseteq v_2$,
        \item for each sequence $(v_k)_{k \in \mathbb{N}}$, the sequence $(v^{\Delta}_k)_{k \in \mathbb{N}}$ defined as $v^{\Delta}_0 = v_0$ and $v^{\Delta}_k = v^{\Delta}_{k-1} \Delta v_k$ reaches a fixpoint after finitely many steps.
    \end{enumerate}
\end{definition}

By different implementation of widening and narrowing, abstract interpreters
employ a different strategies to achieve convergence -- for example widening
with thresholds \cite{Blanchet2003, Lakhdar2011}, delayed widening, parma widening
\cite{Bagnara2008} or abstract acceleration \cite{Gonnord2006, Feautrier2010}.

An alternative approach to tackle infinite interpretation that does not require
any extrapolation operator is a \textbf{\emph{policy iteration}}
\cite{Costan2005, Gaubert2007, Gawlitza2007, Gawlitza2007b, Gawlitza2011}. The
idea of policies is to compute fixpoint solution of a sequence of simpler
semantic equations, such that the least fixpoint is reached after a finite
number of iterations.  The sequence of policies defines a strategy to approach
the fixpoint either from above or below. Policies are formed from a
decomposition of original abstraction.

\begin{marginfigure}
\begin{minted}[linenos]{c}
int i = 10;
int v = 0;
while (i >= 0) {
    i = i - 1;
    if (random())
        v = v + 1;
}
\end{minted}
    \caption{Program that requires a relational invariant.}
    \label{fig:relationalc}
\end{marginfigure}

The drawback of until now presented domains is that they are not able to track
relational properties between variables -- hence we address them as
\emph{non-relational} abstract domains. For example in a program from the
\autoref{fig:relationalc}, to show that $v \leq 11$ at line 7, we need to
prove a relational loop invariant $v + i \leq 10$.

\add{other applications of relational domains: analysis of programs with
symbolic parameters, modular analysis of procedures, inference of non-uniform
non-numerical invariants (pointer analysis)}

\subsection{Relational abstract domains}

linear equalities

polyhedra

octagons

\subsubsection{Term Domain}

\subsubsection{Predicate Abstraction}

\subsection{Weakly relational abstract domains}

\subsubsection{Zone domain}

\subsubsection{Octagon domain}

\subsubsection{Zone congruence domain}

\section{Abstract Operators}

\prule
\bigskip

So far, we have presented only domains, which abstract only scalar values -- we call
them numerical abstract domains.  Overall a \emph{numerical abstract domain} is
determined by three ingredients:
\begin{enumerate}
    \item a poset $(\mathcal{A}, \sqsupseteq)$ with concretisation and abstraction function,
    \item effective and sound abstract operators,
    \item an iteration strategy.
\end{enumerate}

\subsection{Non-numeric abstract domains}


%Later the technique was extended by complementation \cite{Cortesi1995}.

%\section{Abstraction Framework}
%See handbook of model checkin chap. 13

%\subsection{Soundness}
% A principal requirement for any abstraction framework is that it is sound.


% see 13.4.1.1 Specific Abstractions: Examples
% 13.4.2 Additional Reading


\section{Abstraction base techniques}

\subsection{Abstraction-based model checking}

\add{ Abstraction is used in model checking to make model smaller. In general we are talking about overapproximating abstraction, wham mean that if an abstract model is correct the concrete model is also. However there is no guarantee that there is an error when ... }

% reachability algorithm

\subsection{Refinement}

\section{Counterexample-guided abstraction refinement}

% algorithm

% picture

\section{Lazy abstraction}

\section{Eager Abstraction}

\section{Symbolic Abstraction}

\section{Interpolation}

% policy iteration
